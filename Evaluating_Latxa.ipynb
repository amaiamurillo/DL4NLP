{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Evaluating HiTZ/latxa-7b-1v on Sentiment Analysis with Few-Shot Learning Approach"],"metadata":{"id":"5PjaIoJCsyYE"}},{"cell_type":"markdown","source":["This project aims to evaluate the recently released Latxa language model, specifically  [HiTZ/latxa-7b-v1](https://huggingface.co/HiTZ/latxa-7b-v1?library=true), on sentiment analysis using 5-shot learning approach. We also intend to analyze how the use of different prompts impact on the overall performance of the model. Last but not least, we plan to compare the model's performance against its parent model [meta-llama/Llama-2-7b](https://huggingface.co/meta-llama/Llama-2-7b). To this end, we will use [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness/tree/main) framework, which allows a wide range of zero- and few-shot evaluation tasks on autoregressive language models.\n","\n","To get started, we need to fork the [main repository](https://github.com/EleutherAI/lm-evaluation-harness) and clone it. This involves creating a copy of the original repository within our own GitHub account. Then we create a branch with the name of our project, and install the requirements our your environment.\n"],"metadata":{"id":"lnsUo7hntf0u"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1qIlgarDspZb","outputId":"9aa72385-295f-4fd6-f3ce-e2973bf8d753","executionInfo":{"status":"ok","timestamp":1710864118123,"user_tz":-60,"elapsed":17935,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'lm-evaluation-harness'...\n","remote: Enumerating objects: 25444, done.\u001b[K\n","remote: Counting objects: 100% (4264/4264), done.\u001b[K\n","remote: Compressing objects: 100% (549/549), done.\u001b[K\n","remote: Total 25444 (delta 4002), reused 3721 (delta 3715), pack-reused 21180\u001b[K\n","Receiving objects: 100% (25444/25444), 21.52 MiB | 20.79 MiB/s, done.\n","Resolving deltas: 100% (17318/17318), done.\n","/content/lm-evaluation-harness\n","Branch 'DL4NLP' set up to track remote branch 'DL4NLP' from 'origin'.\n","Switched to a new branch 'DL4NLP'\n","Obtaining file:///content/lm-evaluation-harness\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (0.28.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (0.4.1)\n","Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.18.0)\n","Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (4.0.0)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.9.0)\n","Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (0.9.0)\n","Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.11.1)\n","Requirement already satisfied: pytablewriter in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (1.2.0)\n","Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (0.1.2)\n","Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.4.1)\n","Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (1.2.2)\n","Requirement already satisfied: sqlitedict in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.1.0)\n","Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (2.2.1+cu121)\n","Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (0.0.11)\n","Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (4.38.2)\n","Requirement already satisfied: zstandard in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (0.22.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (0.3.8)\n","Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (1.1)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.4.2) (10.1.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (24.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (6.0.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (0.20.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->lm_eval==0.4.2) (0.4.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.13.1)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (0.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (4.66.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->lm_eval==0.4.2) (3.9.3)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate->lm_eval==0.4.2) (0.18.0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (3.8.1)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.4.2) (1.16.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (2.8.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (2023.12.25)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (0.9.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (0.4.6)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm_eval==0.4.2) (4.9.4)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.4.2) (3.3.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8->lm_eval==0.4.2) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->lm_eval==0.4.2) (12.4.99)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.1->lm_eval==0.4.2) (0.15.2)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->lm_eval==0.4.2) (23.2.0)\n","Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.2) (67.7.2)\n","Requirement already satisfied: DataProperty<2,>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.2) (1.0.1)\n","Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.2) (1.1.3)\n","Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.2) (3.2.0)\n","Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.2) (1.3.3)\n","Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.2) (0.1.4)\n","Requirement already satisfied: typepy[datetime]<2,>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from pytablewriter->lm_eval==0.4.2) (1.3.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.3.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->lm_eval==0.4.2) (4.0.3)\n","Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.4.2) (5.2.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.16.0->lm_eval==0.4.2) (2024.2.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.2) (2.8.2)\n","Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.10/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm_eval==0.4.2) (2023.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8->lm_eval==0.4.2) (2.1.5)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score>=0.0.4->lm_eval==0.4.2) (8.1.7)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8->lm_eval==0.4.2) (1.3.0)\n","Building wheels for collected packages: lm_eval\n","  Building editable for lm_eval (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lm_eval: filename=lm_eval-0.4.2-0.editable-py3-none-any.whl size=15076 sha256=d621bd1e06ba3e68c3568926cab2e4f2aafd860d8af98ff1f37f2be424274b28\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-l8norw6m/wheels/dc/8d/a0/ce1a137b6a29fcf5007da91566ee423695e01d20703991091d\n","Successfully built lm_eval\n","Installing collected packages: lm_eval\n","  Attempting uninstall: lm_eval\n","    Found existing installation: lm_eval 0.4.2\n","    Uninstalling lm_eval-0.4.2:\n","      Successfully uninstalled lm_eval-0.4.2\n","Successfully installed lm_eval-0.4.2\n"]}],"source":["!git clone https://github.com/amaiamurillo/lm-evaluation-harness/\n","%cd lm-evaluation-harness\n","!git checkout DL4NLP\n","!pip install -e ."]},{"cell_type":"markdown","source":["Once we have cloned the repository, we create a folder in order to store the tasks we will define later."],"metadata":{"id":"FoWuZdTIuIYw"}},{"cell_type":"code","source":["# Check currenty directory\n","%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"awxVcvu4uHzp","outputId":"9470e0f8-b67b-4e47-b9a1-b5c99bb52626","executionInfo":{"status":"ok","timestamp":1710862965404,"user_tz":-60,"elapsed":5,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/lm-evaluation-harness'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# Change directory\n","%cd lm_eval/tasks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yz4TlFJyuZWc","outputId":"bd390147-ecc1-4327-a096-f2d7daa78f02","executionInfo":{"status":"ok","timestamp":1710864139333,"user_tz":-60,"elapsed":376,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/lm-evaluation-harness/lm_eval/tasks\n"]}]},{"cell_type":"code","source":["# Create new folder\n","!mkdir DL4NLP_project"],"metadata":{"id":"1DDjldCyubZZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Change directory to the newly created folder\n","%cd DL4NLP_project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpFAbAJPudt5","outputId":"58c9ed15-8c49-41e3-de98-d5e479352cef","executionInfo":{"status":"ok","timestamp":1710865373415,"user_tz":-60,"elapsed":639,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/lm-evaluation-harness/lm_eval/tasks/DL4NLP_project\n"]}]},{"cell_type":"markdown","source":["## Prompts"],"metadata":{"id":"hlqbbxLgTs85"}},{"cell_type":"markdown","source":["After creating the folder, we define the tasks for evaluating the model, which should be specified in YAML format. In this case, we will maintain the same configuration across all tasks except for the prompts. This strategy allows us to observe how performance varies with each prompt. We will define 5 tasks, each designed to assess the model's performance using a different prompt."],"metadata":{"id":"SXtfqvFSuzeo"}},{"cell_type":"markdown","source":["### Prompt 1\n","This was the original prompt proposed by HiTZ research center, which can be found in the following repositories: [juletx](https://github.com/juletx/lm-evaluation-harness/blob/eustrivia/lm_eval/tasks/basqueglue/bec.yaml) and [naiarapm](https://github.com/naiarapm/lm-evaluation-harness/blob/basqueglue/lm_eval/tasks/basqueglue/bec.yaml)."],"metadata":{"id":"AIyQ2y0byrnM"}},{"cell_type":"code","source":["# Create the tasks corresponding to the first prompt\n","!touch prompt1.yaml"],"metadata":{"id":"jdgLh1GIujk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Task specifications for prompt 1\n","%%writefile prompt1.yaml\n","group: prompts\n","task: prompt1\n","dataset_path: orai-nlp/basqueGLUE\n","dataset_name: bec\n","output_type: multiple_choice\n","validation_split: validation\n","test_split: test\n","doc_to_text: \"Testua: {{text}}\\nGaldera: Nolako jarrera agertzen du aurreko testuak?\\nErantzuna:\"\n","doc_to_target: label\n","doc_to_choice: ['negatiboa', 'neutrala', 'positiboa']\n","metric_list:\n","  - metric: acc\n","    aggregation: mean\n","    higher_is_better: true\n","metadata:\n","  - version: 1.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OEuHoS2lw51v","outputId":"cdf3708f-eda9-4683-a2bd-1eaeb47dc0bc","executionInfo":{"status":"ok","timestamp":1710865379486,"user_tz":-60,"elapsed":340,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting prompt1.yaml\n"]}]},{"cell_type":"markdown","source":["### Prompt 2\n"],"metadata":{"id":"_3qNXH5Uyupp"}},{"cell_type":"code","source":["# Create the tasks corresponding to the second prompt\n","!touch prompt2.yaml"],"metadata":{"id":"zF010SYmylvb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Task specifications for prompt 2\n","%%writefile prompt2.yaml\n","group: prompts\n","task: prompt2\n","dataset_path: orai-nlp/basqueGLUE\n","dataset_name: bec\n","output_type: multiple_choice\n","validation_split: validation\n","test_split: test\n","doc_to_text: \"Txioa: {{text}}\\nAgindua: Sailkatu aurreko txioa agertzen duen jarraren arabera. \\nJarrera:\"\n","doc_to_target: label\n","doc_to_choice: ['negatiboa', 'neutrala', 'positiboa']\n","metric_list:\n","  - metric: acc\n","    aggregation: mean\n","    higher_is_better: true\n","metadata:\n","  - version: 1.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f868c0ee-f72b-4927-ea0b-e94e91b737eb","id":"Ep1U303wy3IQ","executionInfo":{"status":"ok","timestamp":1710865384695,"user_tz":-60,"elapsed":352,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting prompt2.yaml\n"]}]},{"cell_type":"markdown","source":["### Prompt 3"],"metadata":{"id":"_LAXuskay93B"}},{"cell_type":"code","source":["# Create the tasks corresponding to the third prompt\n","!touch prompt3.yaml"],"metadata":{"id":"DVVXVblSzAtj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Task specifications for prompt 3\n","%%writefile prompt3.yaml\n","group: prompts\n","task: prompt3\n","dataset_path: orai-nlp/basqueGLUE\n","dataset_name: bec\n","output_type: multiple_choice\n","validation_split: validation\n","test_split: test\n","doc_to_text: \"Testua: {{text}}\\nGaldera: Zein da aurreko testuaren tonua: negatiboa, neutrala ala positiboa?\\nErantzuna:\"\n","doc_to_target: label\n","doc_to_choice: ['negatiboa', 'neutrala', 'positiboa']\n","metric_list:\n","  - metric: acc\n","    aggregation: mean\n","    higher_is_better: true\n","metadata:\n","  - version: 1.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d2x324lqzM2K","outputId":"d080903b-841d-4fc8-d5f9-0d3b190508eb","executionInfo":{"status":"ok","timestamp":1710865405414,"user_tz":-60,"elapsed":4,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting prompt3.yaml\n"]}]},{"cell_type":"markdown","source":["### Prompt 4"],"metadata":{"id":"eDrIcjkUYvOh"}},{"cell_type":"code","source":["# Create the tasks corresponding to the fourth prompt\n","!touch prompt4.yaml"],"metadata":{"id":"2YKu3S7rYyEZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Task specifications for prompt 4\n","%%writefile prompt4.yaml\n","group: prompts\n","task: prompt4\n","dataset_path: orai-nlp/basqueGLUE\n","dataset_name: bec\n","output_type: multiple_choice\n","validation_split: validation\n","test_split: test\n","doc_to_text: \"Testua: {{text}}\\nGaldera: Aurreko testuan adierazitako sentimendua negatiboa, neutrala ala positiboa da?\\nErantzuna:\"\n","doc_to_target: label\n","doc_to_choice: ['negatiboa', 'neutrala', 'positiboa']\n","metric_list:\n","  - metric: acc\n","    aggregation: mean\n","    higher_is_better: true\n","metadata:\n","  - version: 1.0"],"metadata":{"id":"Y5hDsYvYZAQ1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710865409204,"user_tz":-60,"elapsed":2,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"e0466163-af81-4640-8d38-c813841e125a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting prompt4.yaml\n"]}]},{"cell_type":"markdown","source":["### Prompt 5"],"metadata":{"id":"-xVNbIAHbhL5"}},{"cell_type":"code","source":["# Create the tasks corresponding to the fifth prompt\n","!touch prompt5.yaml"],"metadata":{"id":"w-sxM7M_bkpD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Task specifications for prompt 5\n","%%writefile prompt5.yaml\n","group: prompts\n","task: prompt5\n","dataset_path: orai-nlp/basqueGLUE\n","dataset_name: bec\n","output_type: multiple_choice\n","validation_split: validation\n","test_split: test\n","doc_to_text: \"Testua: {{text}}\\nGaldera: Nolakoa da aurreko testuaren tonua?\\nErantzuna:\"\n","doc_to_target: label\n","doc_to_choice: ['negatiboa', 'neutrala', 'positiboa']\n","metric_list:\n","  - metric: acc\n","    aggregation: mean\n","    higher_is_better: true\n","metadata:\n","  - version: 1.0"],"metadata":{"id":"Zelkxq-Hbnx5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710865414670,"user_tz":-60,"elapsed":2,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"168377c3-4937-4299-f9f5-5be6d68effa8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting prompt5.yaml\n"]}]},{"cell_type":"markdown","source":["## Evaluate HiTZ/latxa-7b-1v"],"metadata":{"id":"Uzi0j1V60HwW"}},{"cell_type":"markdown","source":["Now that we have defined the prompts, let's evaluate our model using the prompts one by one."],"metadata":{"id":"aD7kXIOsxatt"}},{"cell_type":"markdown","source":["### Prompt 1"],"metadata":{"id":"QiwvfINnOm0T"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=HiTZ/latxa-7b-v1 \\\n","    --tasks prompt1 \\\n","    --device cuda \\\n","    --output_path ./prompt1_latxa.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"id":"_1GexX-u0SCE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b974f9c9-b8bb-4323-bfad-7e29c3e29d9f","executionInfo":{"status":"ok","timestamp":1709838895914,"user_tz":-60,"elapsed":2925853,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-07 18:26:13.711415: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-07 18:26:13.711466: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-07 18:26:13.712804: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-07 18:26:15.384427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-07:18:26:19,774 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-07:18:26:19,774 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-07:18:26:26,952 INFO     [__main__.py:293] Selected Tasks: ['prompt1']\n","2024-03-07:18:26:26,952 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-07:18:26:26,953 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-07:18:26:26,984 INFO     [huggingface.py:162] Using device 'cuda'\n","Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","Loading checkpoint shards: 100% 2/2 [01:13<00:00, 36.51s/it]\n","2024-03-07:18:27:41,807 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","2024-03-07:18:27:45,537 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt1 from None to 5\n","2024-03-07:18:27:45,538 INFO     [task.py:386] Building contexts for prompt1 on rank 0...\n","100% 1302/1302 [00:07<00:00, 175.85it/s]\n","2024-03-07:18:27:53,003 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [46:51<00:00,  1.39it/s]\n","hf (pretrained=HiTZ/latxa-7b-v1), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt1|Yaml   |none  |     5|acc   |0.5561|±  |0.0138|\n","\n"]}]},{"cell_type":"markdown","source":["We will save the results in JSON format."],"metadata":{"id":"RYddk0lUB2oA"}},{"cell_type":"code","source":["from google.colab import files\n","\n","files.download('pretrained__HiTZ__latxa-7b-v1_prompt1.jsonl')\n","files.download('prompt1_latxa.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"0y_2PGPSk3O5","executionInfo":{"status":"ok","timestamp":1709838947129,"user_tz":-60,"elapsed":862,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"d41777eb-f4c6-4385-a6e4-b0cb09b933ed"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f3912d7d-fabb-463e-8402-801d86b89c4d\", \"pretrained__HiTZ__latxa-7b-v1_prompt1.jsonl\", 5480577)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_11eec78b-871d-4f40-a311-b459df3d84fc\", \"prompt1_latxa.json\", 5376)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Prompt 2"],"metadata":{"id":"xVCrr9PHWgTL"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=HiTZ/latxa-7b-v1 \\\n","    --tasks prompt2 \\\n","    --device cuda \\\n","    --output_path ./prompt2_latxa.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ak5amDZoWX64","executionInfo":{"status":"ok","timestamp":1709829472179,"user_tz":-60,"elapsed":3021247,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"7d6e5e5a-b5cc-439e-ac17-4dbf947ea223"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-07 15:47:34.783246: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-07 15:47:34.783306: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-07 15:47:34.784811: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-07 15:47:36.240417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-07:15:47:41,722 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-07:15:47:41,722 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-07:15:47:48,358 INFO     [__main__.py:293] Selected Tasks: ['prompt2']\n","2024-03-07:15:47:48,358 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-07:15:47:48,359 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-07:15:47:48,390 INFO     [huggingface.py:162] Using device 'cuda'\n","Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","Loading checkpoint shards: 100% 2/2 [01:07<00:00, 33.58s/it]\n","2024-03-07:15:48:57,208 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","2024-03-07:15:49:00,922 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt2 from None to 5\n","2024-03-07:15:49:00,923 INFO     [task.py:386] Building contexts for prompt2 on rank 0...\n","100% 1302/1302 [00:07<00:00, 169.54it/s]\n","2024-03-07:15:49:08,663 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [48:30<00:00,  1.34it/s]\n","hf (pretrained=HiTZ/latxa-7b-v1), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt2|Yaml   |none  |     5|acc   |0.5453|±  |0.0138|\n","\n"]}]},{"cell_type":"code","source":["files.download('pretrained__HiTZ__latxa-7b-v1_prompt2.jsonl')\n","files.download('prompt2_latxa.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"tONSoERVyibo","executionInfo":{"status":"ok","timestamp":1709835800759,"user_tz":-60,"elapsed":446,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"bc653134-50bf-4d41-f259-42492b29e021"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_ded5ff24-15d9-448f-9090-79f856f71d89\", \"pretrained__HiTZ__latxa-7b-v1_prompt2.jsonl\", 5691933)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_2ecb0488-2842-4de4-8422-7d4fa987dc8f\", \"prompt2_latxa.json\", 5385)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Prompt 3"],"metadata":{"id":"Ur5N-7nQWjuK"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=HiTZ/latxa-7b-v1 \\\n","    --tasks prompt3 \\\n","    --device cuda \\\n","    --output_path ./prompt3_latxa.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BUq7kNNiWeaX","executionInfo":{"status":"ok","timestamp":1709832887057,"user_tz":-60,"elapsed":3058709,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"e47e600e-82a4-4d8c-9b79-bb28b0f946db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-07 16:43:52.750128: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-07 16:43:52.750194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-07 16:43:52.753467: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-07 16:43:54.678528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-07:16:44:00,589 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-07:16:44:00,590 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-07:16:44:08,378 INFO     [__main__.py:293] Selected Tasks: ['prompt3']\n","2024-03-07:16:44:08,378 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-07:16:44:08,380 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-07:16:44:08,411 INFO     [huggingface.py:162] Using device 'cuda'\n","Loading checkpoint shards:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","Loading checkpoint shards: 100% 2/2 [01:16<00:00, 38.11s/it]\n","2024-03-07:16:45:26,274 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","2024-03-07:16:45:29,692 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt3 from None to 5\n","2024-03-07:16:45:29,692 INFO     [task.py:386] Building contexts for prompt3 on rank 0...\n","100% 1302/1302 [00:06<00:00, 188.08it/s]\n","2024-03-07:16:45:36,658 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [48:56<00:00,  1.33it/s]\n","hf (pretrained=HiTZ/latxa-7b-v1), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt3|Yaml   |none  |     5|acc   |0.5653|±  |0.0137|\n","\n"]}]},{"cell_type":"code","source":["files.download('pretrained__HiTZ__latxa-7b-v1_prompt3.jsonl')\n","files.download('prompt3_latxa.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"Tk-RpURBJw6K","executionInfo":{"status":"ok","timestamp":1709835825949,"user_tz":-60,"elapsed":435,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"7f0bef36-7153-497e-fe6c-e1477c33af19"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_f175fbed-e6a1-4e93-858e-682191c38dca\", \"pretrained__HiTZ__latxa-7b-v1_prompt3.jsonl\", 6043689)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_26a822ea-7718-49e0-a1a0-2ebea0b5fdfb\", \"prompt3_latxa.json\", 5399)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Prompt 4"],"metadata":{"id":"DT99HmxyaROW"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=HiTZ/latxa-7b-v1 \\\n","    --tasks prompt4 \\\n","    --device cuda \\\n","    --output_path ./prompt4_latxa.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R_kcd_t4aU3F","outputId":"0cc9b3f7-7dc9-4b6e-ca2a-0230a3607ab6","executionInfo":{"status":"ok","timestamp":1710851360613,"user_tz":-60,"elapsed":204341,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-19 11:31:00.444261: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-19 11:31:00.444314: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-19 11:31:00.445655: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-19 11:31:01.665103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 20.7MB/s]\n","2024-03-19:11:31:08,640 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-19:11:31:08,640 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-19:11:31:14,065 INFO     [__main__.py:293] Selected Tasks: ['prompt4']\n","2024-03-19:11:31:14,065 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-19:11:31:14,071 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-19:11:31:14,138 INFO     [huggingface.py:162] Using device 'cuda'\n","config.json: 100% 601/601 [00:00<00:00, 3.33MB/s]\n","pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 76.4MB/s]\n","Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n","pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   0% 10.5M/9.98G [00:01<18:05, 9.18MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   0% 21.0M/9.98G [00:01<11:00, 15.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   0% 31.5M/9.98G [00:01<08:45, 18.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   0% 41.9M/9.98G [00:02<08:05, 20.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 52.4M/9.98G [00:02<07:50, 21.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 62.9M/9.98G [00:03<07:11, 23.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 73.4M/9.98G [00:03<06:47, 24.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 83.9M/9.98G [00:04<06:42, 24.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 94.4M/9.98G [00:04<06:27, 25.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 105M/9.98G [00:04<06:22, 25.8MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 115M/9.98G [00:05<06:44, 24.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 126M/9.98G [00:05<06:29, 25.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 136M/9.98G [00:06<06:20, 25.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 147M/9.98G [00:06<06:10, 26.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 157M/9.98G [00:06<06:06, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 168M/9.98G [00:07<06:01, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 178M/9.98G [00:07<05:59, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 189M/9.98G [00:07<05:55, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 199M/9.98G [00:08<05:55, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 210M/9.98G [00:08<05:59, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 220M/9.98G [00:09<06:00, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 231M/9.98G [00:09<05:58, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 241M/9.98G [00:09<05:56, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 252M/9.98G [00:10<05:55, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 262M/9.98G [00:10<05:59, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 273M/9.98G [00:11<06:21, 25.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 283M/9.98G [00:11<06:10, 26.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 294M/9.98G [00:11<06:04, 26.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 304M/9.98G [00:12<05:58, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 315M/9.98G [00:12<05:55, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 325M/9.98G [00:12<05:54, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 336M/9.98G [00:13<05:52, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 346M/9.98G [00:13<05:51, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 357M/9.98G [00:14<05:49, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 367M/9.98G [00:14<05:48, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 377M/9.98G [00:14<05:47, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 388M/9.98G [00:15<05:50, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 398M/9.98G [00:15<05:49, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 409M/9.98G [00:16<05:53, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 419M/9.98G [00:16<05:50, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 430M/9.98G [00:16<05:47, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 440M/9.98G [00:17<05:50, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 451M/9.98G [00:17<07:42, 20.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 461M/9.98G [00:18<07:06, 22.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 472M/9.98G [00:18<07:16, 21.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 482M/9.98G [00:19<06:48, 23.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 493M/9.98G [00:19<06:29, 24.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 503M/9.98G [00:20<06:16, 25.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 514M/9.98G [00:20<06:05, 25.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 524M/9.98G [00:20<05:57, 26.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 535M/9.98G [00:21<05:52, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 545M/9.98G [00:21<05:52, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 556M/9.98G [00:21<05:46, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 566M/9.98G [00:22<05:43, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 577M/9.98G [00:22<05:41, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 587M/9.98G [00:23<05:42, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 598M/9.98G [00:23<05:40, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 608M/9.98G [00:23<05:41, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 619M/9.98G [00:24<06:11, 25.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 629M/9.98G [00:24<06:00, 25.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 640M/9.98G [00:25<05:52, 26.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 650M/9.98G [00:25<05:47, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 661M/9.98G [00:25<05:43, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 671M/9.98G [00:26<05:41, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 682M/9.98G [00:26<05:40, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 692M/9.98G [00:26<05:37, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 703M/9.98G [00:27<05:35, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 713M/9.98G [00:27<05:35, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 724M/9.98G [00:28<05:34, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 734M/9.98G [00:28<05:38, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 744M/9.98G [00:28<05:31, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 755M/9.98G [00:29<05:32, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 765M/9.98G [00:29<05:46, 26.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 776M/9.98G [00:30<05:35, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 786M/9.98G [00:30<05:37, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 797M/9.98G [00:30<05:44, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 807M/9.98G [00:31<05:40, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 818M/9.98G [00:31<05:53, 25.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 828M/9.98G [00:32<05:46, 26.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 839M/9.98G [00:32<05:41, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 849M/9.98G [00:32<05:37, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 860M/9.98G [00:33<05:34, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 870M/9.98G [00:33<05:32, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 881M/9.98G [00:33<05:32, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 891M/9.98G [00:34<05:29, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 902M/9.98G [00:34<05:30, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 912M/9.98G [00:35<05:29, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 923M/9.98G [00:35<05:32, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 933M/9.98G [00:35<05:26, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 944M/9.98G [00:36<05:26, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 954M/9.98G [00:36<05:29, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 965M/9.98G [00:36<05:28, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 975M/9.98G [00:37<05:26, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 986M/9.98G [00:37<05:26, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 996M/9.98G [00:38<05:26, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 1.01G/9.98G [00:38<05:24, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 1.02G/9.98G [00:38<05:24, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 1.03G/9.98G [00:39<05:23, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 1.04G/9.98G [00:39<05:23, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.05G/9.98G [00:40<05:24, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.06G/9.98G [00:40<05:26, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.07G/9.98G [00:40<05:24, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.08G/9.98G [00:41<05:27, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:41<05:26, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.10G/9.98G [00:41<05:35, 26.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.11G/9.98G [00:42<05:23, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.12G/9.98G [00:42<05:22, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.13G/9.98G [00:43<05:25, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.14G/9.98G [00:43<05:25, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.15G/9.98G [00:43<05:23, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.16G/9.98G [00:44<05:21, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.17G/9.98G [00:44<05:20, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.18G/9.98G [00:45<05:20, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.20G/9.98G [00:45<05:23, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.21G/9.98G [00:45<05:21, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.22G/9.98G [00:46<05:21, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.23G/9.98G [00:46<05:22, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.24G/9.98G [00:46<05:19, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.25G/9.98G [00:47<05:21, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.26G/9.98G [00:47<05:21, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.27G/9.98G [00:48<05:22, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.28G/9.98G [00:48<05:19, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.29G/9.98G [00:48<05:18, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.30G/9.98G [00:49<05:16, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.31G/9.98G [00:49<05:17, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.32G/9.98G [00:50<05:16, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.33G/9.98G [00:50<05:16, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.34G/9.98G [00:50<05:14, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.35G/9.98G [00:51<05:13, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.36G/9.98G [00:51<05:12, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.37G/9.98G [00:51<05:12, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.38G/9.98G [00:52<05:13, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.39G/9.98G [00:52<05:12, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.41G/9.98G [00:53<05:15, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.42G/9.98G [00:53<05:15, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.43G/9.98G [00:53<05:17, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.44G/9.98G [00:54<05:13, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.45G/9.98G [00:54<05:12, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.46G/9.98G [00:55<05:12, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.47G/9.98G [00:55<05:11, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.48G/9.98G [00:55<05:08, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.49G/9.98G [00:56<05:08, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.50G/9.98G [00:56<05:06, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.51G/9.98G [00:56<05:06, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.52G/9.98G [00:57<05:06, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.53G/9.98G [00:57<05:05, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.54G/9.98G [00:58<05:06, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.55G/9.98G [00:58<05:08, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.56G/9.98G [00:58<05:13, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.57G/9.98G [00:59<05:03, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.58G/9.98G [00:59<05:06, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.59G/9.98G [00:59<05:05, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.60G/9.98G [01:00<05:19, 26.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.61G/9.98G [01:00<04:58, 28.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.63G/9.98G [01:01<04:59, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.64G/9.98G [01:01<04:59, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.65G/9.98G [01:01<05:10, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.66G/9.98G [01:02<04:57, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.67G/9.98G [01:02<04:59, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.68G/9.98G [01:03<05:07, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.69G/9.98G [01:03<04:58, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.70G/9.98G [01:03<04:58, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.71G/9.98G [01:04<04:59, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.72G/9.98G [01:04<04:58, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.73G/9.98G [01:04<04:59, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.74G/9.98G [01:05<04:59, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.75G/9.98G [01:05<05:02, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.76G/9.98G [01:06<05:00, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.77G/9.98G [01:06<05:00, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.78G/9.98G [01:06<05:01, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.79G/9.98G [01:07<05:03, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.80G/9.98G [01:07<05:02, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.81G/9.98G [01:08<05:00, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.82G/9.98G [01:08<04:59, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.84G/9.98G [01:08<04:58, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.85G/9.98G [01:09<04:59, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.86G/9.98G [01:09<04:58, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [01:09<04:56, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.88G/9.98G [01:10<04:55, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.89G/9.98G [01:10<04:57, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.90G/9.98G [01:11<04:55, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.91G/9.98G [01:11<04:54, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.92G/9.98G [01:11<04:54, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [01:12<04:56, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.94G/9.98G [01:12<04:52, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 1.95G/9.98G [01:12<04:51, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 1.96G/9.98G [01:13<05:20, 25.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 1.97G/9.98G [01:13<04:44, 28.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 1.98G/9.98G [01:14<04:45, 28.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 1.99G/9.98G [01:14<04:49, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 2.00G/9.98G [01:14<04:53, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 2.01G/9.98G [01:15<04:54, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 2.02G/9.98G [01:15<04:53, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 2.03G/9.98G [01:16<04:52, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 2.04G/9.98G [01:16<04:52, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.06G/9.98G [01:16<04:51, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.07G/9.98G [01:17<04:52, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.08G/9.98G [01:17<04:48, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.09G/9.98G [01:18<04:49, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.10G/9.98G [01:18<04:48, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.11G/9.98G [01:18<04:46, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.12G/9.98G [01:19<04:47, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.13G/9.98G [01:19<04:45, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.14G/9.98G [01:19<04:48, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.15G/9.98G [01:20<04:47, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [01:20<04:48, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.17G/9.98G [01:21<04:46, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.18G/9.98G [01:21<04:45, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.19G/9.98G [01:21<04:44, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.20G/9.98G [01:22<04:43, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.21G/9.98G [01:22<04:50, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.22G/9.98G [01:23<04:38, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.23G/9.98G [01:23<04:38, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.24G/9.98G [01:23<04:49, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.25G/9.98G [01:24<04:38, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.26G/9.98G [01:24<04:38, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.28G/9.98G [01:24<04:41, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.29G/9.98G [01:25<04:36, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.30G/9.98G [01:25<04:39, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.31G/9.98G [01:26<04:51, 26.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.32G/9.98G [01:26<04:36, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.33G/9.98G [01:26<04:37, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.34G/9.98G [01:27<04:37, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.35G/9.98G [01:27<04:38, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.36G/9.98G [01:27<04:36, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.37G/9.98G [01:28<04:37, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.38G/9.98G [01:28<04:35, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.39G/9.98G [01:29<04:35, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.40G/9.98G [01:29<04:34, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.41G/9.98G [01:29<04:38, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.42G/9.98G [01:30<04:36, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.43G/9.98G [01:30<04:34, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.44G/9.98G [01:31<04:35, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.45G/9.98G [01:31<04:34, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.46G/9.98G [01:31<04:34, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.47G/9.98G [01:32<04:35, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.49G/9.98G [01:32<04:33, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.50G/9.98G [01:32<04:32, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.51G/9.98G [01:33<04:33, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.52G/9.98G [01:33<04:32, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.53G/9.98G [01:34<04:31, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.54G/9.98G [01:34<04:30, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.55G/9.98G [01:34<04:35, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.56G/9.98G [01:35<04:33, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.57G/9.98G [01:35<04:33, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.58G/9.98G [01:36<04:30, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.59G/9.98G [01:36<04:32, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.60G/9.98G [01:36<04:32, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.61G/9.98G [01:37<04:30, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.62G/9.98G [01:37<04:36, 26.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.63G/9.98G [01:37<04:30, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.64G/9.98G [01:38<04:28, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.65G/9.98G [01:38<04:26, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.66G/9.98G [01:39<04:26, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.67G/9.98G [01:39<04:25, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.68G/9.98G [01:39<04:24, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.69G/9.98G [01:40<04:23, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.71G/9.98G [01:40<04:24, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.72G/9.98G [01:41<04:22, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.73G/9.98G [01:41<04:21, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.74G/9.98G [01:41<04:20, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [01:42<04:22, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.76G/9.98G [01:42<04:21, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.77G/9.98G [01:42<04:21, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.78G/9.98G [01:43<04:31, 26.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.79G/9.98G [01:43<04:19, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.80G/9.98G [01:44<04:19, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.81G/9.98G [01:44<04:26, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.82G/9.98G [01:44<04:17, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.83G/9.98G [01:45<04:19, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.84G/9.98G [01:45<04:18, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.85G/9.98G [01:45<04:18, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.86G/9.98G [01:46<04:19, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.87G/9.98G [01:46<04:25, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.88G/9.98G [01:47<04:16, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.89G/9.98G [01:47<04:16, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.90G/9.98G [01:47<04:15, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.92G/9.98G [01:48<04:17, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.93G/9.98G [01:48<04:15, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.94G/9.98G [01:49<04:16, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.95G/9.98G [01:49<04:18, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.96G/9.98G [01:49<04:18, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.97G/9.98G [01:50<04:18, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.98G/9.98G [01:50<04:17, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.99G/9.98G [01:50<04:16, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 3.00G/9.98G [01:51<04:18, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 3.01G/9.98G [01:51<04:17, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 3.02G/9.98G [01:52<04:17, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 3.03G/9.98G [01:52<04:15, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 3.04G/9.98G [01:52<04:13, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.05G/9.98G [01:53<04:12, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.06G/9.98G [01:53<04:12, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.07G/9.98G [01:54<04:10, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.08G/9.98G [01:54<04:09, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.09G/9.98G [01:54<04:09, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.10G/9.98G [01:55<04:09, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.11G/9.98G [01:55<04:08, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.12G/9.98G [01:55<04:09, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.14G/9.98G [01:56<04:08, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.15G/9.98G [01:56<04:06, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.16G/9.98G [01:57<04:06, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.17G/9.98G [01:57<04:07, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.18G/9.98G [01:57<04:08, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.19G/9.98G [01:58<04:07, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.20G/9.98G [01:58<04:05, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.21G/9.98G [01:58<04:05, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.22G/9.98G [01:59<04:05, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.23G/9.98G [01:59<04:04, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.24G/9.98G [02:00<04:04, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.25G/9.98G [02:00<04:03, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.26G/9.98G [02:00<04:03, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.27G/9.98G [02:01<04:02, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.28G/9.98G [02:01<04:03, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.29G/9.98G [02:02<04:02, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.30G/9.98G [02:02<04:03, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.31G/9.98G [02:02<04:02, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.32G/9.98G [02:03<04:03, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.33G/9.98G [02:03<04:03, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.34G/9.98G [02:03<04:01, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.36G/9.98G [02:04<04:03, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.37G/9.98G [02:04<04:02, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.38G/9.98G [02:05<04:01, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.39G/9.98G [02:05<04:02, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.40G/9.98G [02:05<04:01, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.41G/9.98G [02:06<04:00, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.42G/9.98G [02:06<03:59, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.43G/9.98G [02:07<03:59, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.44G/9.98G [02:07<04:08, 26.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [02:07<04:04, 26.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.46G/9.98G [02:08<04:03, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.47G/9.98G [02:08<04:00, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.48G/9.98G [02:08<03:59, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.49G/9.98G [02:09<03:57, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.50G/9.98G [02:09<03:56, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.51G/9.98G [02:10<03:56, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.52G/9.98G [02:10<03:54, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.53G/9.98G [02:10<03:53, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.54G/9.98G [02:11<03:53, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.55G/9.98G [02:11<03:51, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.57G/9.98G [02:12<03:50, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.58G/9.98G [02:12<03:54, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.59G/9.98G [02:12<03:53, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.60G/9.98G [02:13<03:52, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.61G/9.98G [02:13<03:53, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.62G/9.98G [02:13<03:51, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.63G/9.98G [02:14<03:56, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.64G/9.98G [02:14<03:56, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.65G/9.98G [02:15<03:56, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.66G/9.98G [02:15<03:57, 26.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.67G/9.98G [02:15<03:52, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.68G/9.98G [02:16<03:50, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.69G/9.98G [02:16<03:48, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [02:17<03:47, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.71G/9.98G [02:17<03:51, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.72G/9.98G [02:17<03:49, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.73G/9.98G [02:18<03:48, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.74G/9.98G [02:18<03:47, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.75G/9.98G [02:18<03:46, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.76G/9.98G [02:19<03:45, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.77G/9.98G [02:19<03:47, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.79G/9.98G [02:20<03:45, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.80G/9.98G [02:20<03:47, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.81G/9.98G [02:20<03:44, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.82G/9.98G [02:21<03:43, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.83G/9.98G [02:21<03:43, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.84G/9.98G [02:22<03:43, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.85G/9.98G [02:22<03:41, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.86G/9.98G [02:22<03:41, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.87G/9.98G [02:23<03:40, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.88G/9.98G [02:23<03:40, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.89G/9.98G [02:23<03:41, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.90G/9.98G [02:24<03:40, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.91G/9.98G [02:24<03:39, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.92G/9.98G [02:25<03:39, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.93G/9.98G [02:25<03:38, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.94G/9.98G [02:25<03:38, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.95G/9.98G [02:26<03:41, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.96G/9.98G [02:26<03:41, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.97G/9.98G [02:26<03:37, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.98G/9.98G [02:27<03:36, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 4.00G/9.98G [02:27<03:38, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 4.01G/9.98G [02:28<04:35, 21.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 4.02G/9.98G [02:28<04:15, 23.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 4.03G/9.98G [02:29<04:03, 24.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 4.04G/9.98G [02:29<03:54, 25.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.05G/9.98G [02:29<03:48, 26.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.06G/9.98G [02:30<03:43, 26.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.07G/9.98G [02:30<03:39, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.08G/9.98G [02:31<03:37, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.09G/9.98G [02:31<03:37, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.10G/9.98G [02:31<03:34, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.11G/9.98G [02:32<03:34, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.12G/9.98G [02:32<03:33, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.13G/9.98G [02:33<03:33, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.14G/9.98G [02:33<03:31, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.15G/9.98G [02:33<03:31, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.16G/9.98G [02:34<03:30, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.17G/9.98G [02:34<03:30, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.18G/9.98G [02:34<03:37, 26.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.19G/9.98G [02:35<03:35, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.20G/9.98G [02:35<03:41, 26.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.22G/9.98G [02:36<03:37, 26.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.23G/9.98G [02:36<03:36, 26.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.24G/9.98G [02:36<03:32, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.25G/9.98G [02:37<03:30, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.26G/9.98G [02:37<03:29, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.27G/9.98G [02:38<03:28, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.28G/9.98G [02:38<03:27, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.29G/9.98G [02:38<03:26, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.30G/9.98G [02:39<03:26, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.31G/9.98G [02:39<03:26, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.32G/9.98G [02:39<03:25, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.33G/9.98G [02:40<03:24, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.34G/9.98G [02:40<03:23, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.35G/9.98G [02:41<03:22, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.36G/9.98G [02:41<03:22, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.37G/9.98G [02:41<03:39, 25.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.38G/9.98G [02:42<03:17, 28.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.39G/9.98G [02:42<03:17, 28.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.40G/9.98G [02:43<03:41, 25.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.41G/9.98G [02:43<03:12, 28.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.42G/9.98G [02:43<03:20, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.44G/9.98G [02:44<03:22, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.45G/9.98G [02:44<03:22, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.46G/9.98G [02:44<03:26, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.47G/9.98G [02:45<03:23, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.48G/9.98G [02:45<03:22, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.49G/9.98G [02:46<03:25, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.50G/9.98G [02:46<03:27, 26.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.51G/9.98G [02:46<03:20, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.52G/9.98G [02:47<03:18, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.53G/9.98G [02:47<03:18, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.54G/9.98G [02:48<03:19, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.55G/9.98G [02:48<03:18, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.56G/9.98G [02:48<03:18, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.57G/9.98G [02:49<03:17, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.58G/9.98G [02:49<03:16, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.59G/9.98G [02:49<03:19, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.60G/9.98G [02:50<03:14, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.61G/9.98G [02:50<03:14, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.62G/9.98G [02:51<03:14, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.63G/9.98G [02:51<03:15, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.65G/9.98G [02:51<03:12, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.66G/9.98G [02:52<03:13, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.67G/9.98G [02:52<03:12, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.68G/9.98G [02:53<03:12, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.69G/9.98G [02:53<03:14, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.70G/9.98G [02:53<03:13, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.71G/9.98G [02:54<03:13, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.72G/9.98G [02:54<03:13, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.73G/9.98G [02:54<03:12, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.74G/9.98G [02:55<03:11, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.75G/9.98G [02:55<03:12, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.76G/9.98G [02:56<03:11, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.77G/9.98G [02:56<03:09, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.78G/9.98G [02:56<03:11, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.79G/9.98G [02:57<03:08, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.80G/9.98G [02:57<03:07, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.81G/9.98G [02:57<03:06, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.82G/9.98G [02:58<03:07, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.83G/9.98G [02:58<03:07, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.84G/9.98G [02:59<03:09, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.85G/9.98G [02:59<03:06, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.87G/9.98G [02:59<03:06, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.88G/9.98G [03:00<03:06, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.89G/9.98G [03:00<03:08, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.90G/9.98G [03:01<03:07, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.91G/9.98G [03:01<03:05, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.92G/9.98G [03:01<03:04, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.93G/9.98G [03:02<03:05, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.94G/9.98G [03:02<03:04, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.95G/9.98G [03:02<03:04, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.96G/9.98G [03:03<03:03, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.97G/9.98G [03:03<03:02, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.98G/9.98G [03:04<03:02, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.99G/9.98G [03:04<03:02, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 5.00G/9.98G [03:04<03:01, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 5.01G/9.98G [03:05<03:01, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 5.02G/9.98G [03:05<03:01, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 5.03G/9.98G [03:06<03:00, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.04G/9.98G [03:06<02:59, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.05G/9.98G [03:06<02:58, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.06G/9.98G [03:07<03:02, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.08G/9.98G [03:07<02:58, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.09G/9.98G [03:07<02:56, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.10G/9.98G [03:08<03:03, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.11G/9.98G [03:08<02:54, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.12G/9.98G [03:09<02:56, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.13G/9.98G [03:09<02:55, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.14G/9.98G [03:09<02:55, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.15G/9.98G [03:10<02:54, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.16G/9.98G [03:10<02:53, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.17G/9.98G [03:11<02:53, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.18G/9.98G [03:11<02:59, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.19G/9.98G [03:11<02:53, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.20G/9.98G [03:12<02:52, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.21G/9.98G [03:12<02:52, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.22G/9.98G [03:12<02:53, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.23G/9.98G [03:13<02:54, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.24G/9.98G [03:13<02:54, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.25G/9.98G [03:14<02:52, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.26G/9.98G [03:14<02:51, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.27G/9.98G [03:14<02:52, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.28G/9.98G [03:15<02:52, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.30G/9.98G [03:15<02:51, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.31G/9.98G [03:16<02:50, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.32G/9.98G [03:16<02:50, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.33G/9.98G [03:16<02:50, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.34G/9.98G [03:17<02:49, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.35G/9.98G [03:17<02:49, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.36G/9.98G [03:17<02:48, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.37G/9.98G [03:18<02:48, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.38G/9.98G [03:18<02:47, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.39G/9.98G [03:19<02:46, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.40G/9.98G [03:19<02:46, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.41G/9.98G [03:19<02:45, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.42G/9.98G [03:20<02:45, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.43G/9.98G [03:20<02:45, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.44G/9.98G [03:20<02:46, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.45G/9.98G [03:21<02:46, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.46G/9.98G [03:21<02:45, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.47G/9.98G [03:22<02:44, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.48G/9.98G [03:22<02:43, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.49G/9.98G [03:22<02:43, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.51G/9.98G [03:23<02:42, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.52G/9.98G [03:23<02:41, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.53G/9.98G [03:24<02:41, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.54G/9.98G [03:24<02:42, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.55G/9.98G [03:24<02:40, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.56G/9.98G [03:25<02:39, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.57G/9.98G [03:25<02:44, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.58G/9.98G [03:25<02:37, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.59G/9.98G [03:26<02:38, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.60G/9.98G [03:26<02:38, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.61G/9.98G [03:27<02:38, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.62G/9.98G [03:27<02:38, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.63G/9.98G [03:27<02:39, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.64G/9.98G [03:28<02:38, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.65G/9.98G [03:28<02:37, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.66G/9.98G [03:28<02:36, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.67G/9.98G [03:29<02:36, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.68G/9.98G [03:29<02:36, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.69G/9.98G [03:30<02:36, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.70G/9.98G [03:30<02:35, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.71G/9.98G [03:30<02:34, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.73G/9.98G [03:31<02:35, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.74G/9.98G [03:31<02:35, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.75G/9.98G [03:32<02:36, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.76G/9.98G [03:32<02:35, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.77G/9.98G [03:32<02:34, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.78G/9.98G [03:33<02:34, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.79G/9.98G [03:33<02:33, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.80G/9.98G [03:33<02:32, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.81G/9.98G [03:34<02:31, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.82G/9.98G [03:34<02:30, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.83G/9.98G [03:35<02:34, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.84G/9.98G [03:35<02:31, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.85G/9.98G [03:35<02:34, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.86G/9.98G [03:36<02:30, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.87G/9.98G [03:36<02:29, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.88G/9.98G [03:37<02:29, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.89G/9.98G [03:37<02:28, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.90G/9.98G [03:37<02:28, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.91G/9.98G [03:38<02:27, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.92G/9.98G [03:38<02:27, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.93G/9.98G [03:38<02:25, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 5.95G/9.98G [03:39<02:25, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 5.96G/9.98G [03:39<02:25, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 5.97G/9.98G [03:40<02:24, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 5.98G/9.98G [03:40<02:26, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 5.99G/9.98G [03:40<02:25, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 6.00G/9.98G [03:41<02:25, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 6.01G/9.98G [03:41<02:24, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 6.02G/9.98G [03:42<02:23, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 6.03G/9.98G [03:42<02:23, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.04G/9.98G [03:42<02:22, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.05G/9.98G [03:43<02:22, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.06G/9.98G [03:43<02:23, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.07G/9.98G [03:43<02:23, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.08G/9.98G [03:44<02:22, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.09G/9.98G [03:44<02:22, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.10G/9.98G [03:45<02:21, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.11G/9.98G [03:45<02:21, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.12G/9.98G [03:45<02:24, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.13G/9.98G [03:46<02:23, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.14G/9.98G [03:46<02:21, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.16G/9.98G [03:47<02:21, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.17G/9.98G [03:47<02:20, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.18G/9.98G [03:47<02:18, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.19G/9.98G [03:48<02:18, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.20G/9.98G [03:48<02:19, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.21G/9.98G [03:48<02:19, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.22G/9.98G [03:49<02:18, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.23G/9.98G [03:49<02:17, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.24G/9.98G [03:50<02:17, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.25G/9.98G [03:50<02:16, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.26G/9.98G [03:50<02:15, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.27G/9.98G [03:51<02:14, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.28G/9.98G [03:51<02:15, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.29G/9.98G [03:52<02:14, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.30G/9.98G [03:52<02:13, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.31G/9.98G [03:52<02:19, 26.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.32G/9.98G [03:53<02:09, 28.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.33G/9.98G [03:53<02:10, 28.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.34G/9.98G [03:53<02:09, 28.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.35G/9.98G [03:54<02:10, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.36G/9.98G [03:54<02:09, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.38G/9.98G [03:55<02:09, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.39G/9.98G [03:55<02:09, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.40G/9.98G [03:55<02:08, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.41G/9.98G [03:56<02:08, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.42G/9.98G [03:56<02:09, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.43G/9.98G [03:56<02:10, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.44G/9.98G [03:57<02:13, 26.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.45G/9.98G [03:57<02:11, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.46G/9.98G [03:58<02:09, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.47G/9.98G [03:58<02:09, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.48G/9.98G [03:58<02:08, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.49G/9.98G [03:59<02:07, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.50G/9.98G [03:59<02:06, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.51G/9.98G [04:00<02:06, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.52G/9.98G [04:00<02:07, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.53G/9.98G [04:00<02:08, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.54G/9.98G [04:01<02:07, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.55G/9.98G [04:01<02:06, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.56G/9.98G [04:01<02:06, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.57G/9.98G [04:02<02:03, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.59G/9.98G [04:02<02:02, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.60G/9.98G [04:03<02:03, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.61G/9.98G [04:03<02:03, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.62G/9.98G [04:03<02:02, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.63G/9.98G [04:04<02:02, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.64G/9.98G [04:04<02:01, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.65G/9.98G [04:05<02:02, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.66G/9.98G [04:05<02:01, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.67G/9.98G [04:05<02:00, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.68G/9.98G [04:06<01:59, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.69G/9.98G [04:06<02:00, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.70G/9.98G [04:06<01:59, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.71G/9.98G [04:07<01:58, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.72G/9.98G [04:07<01:57, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.73G/9.98G [04:08<01:57, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.74G/9.98G [04:08<01:56, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.75G/9.98G [04:08<01:56, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.76G/9.98G [04:09<01:57, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.77G/9.98G [04:09<01:59, 26.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.78G/9.98G [04:09<01:55, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.79G/9.98G [04:10<01:55, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.81G/9.98G [04:10<01:54, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.82G/9.98G [04:11<01:54, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.83G/9.98G [04:11<01:54, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.84G/9.98G [04:11<01:55, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.85G/9.98G [04:12<01:54, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.86G/9.98G [04:12<01:53, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.87G/9.98G [04:13<01:53, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.88G/9.98G [04:13<01:53, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.89G/9.98G [04:13<01:54, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.90G/9.98G [04:14<01:51, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.91G/9.98G [04:14<01:51, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.92G/9.98G [04:14<01:51, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.93G/9.98G [04:15<01:50, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.94G/9.98G [04:15<01:51, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.95G/9.98G [04:16<01:50, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.96G/9.98G [04:16<01:51, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.97G/9.98G [04:16<01:51, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.98G/9.98G [04:17<01:49, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.99G/9.98G [04:17<01:48, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 7.00G/9.98G [04:18<01:48, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 7.01G/9.98G [04:18<01:47, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 7.03G/9.98G [04:18<01:55, 25.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.04G/9.98G [04:19<01:44, 28.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.05G/9.98G [04:19<01:45, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.06G/9.98G [04:19<01:46, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.07G/9.98G [04:20<01:46, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.08G/9.98G [04:20<01:45, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.09G/9.98G [04:21<01:45, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.10G/9.98G [04:21<01:44, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.11G/9.98G [04:21<01:44, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.12G/9.98G [04:22<01:43, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.13G/9.98G [04:22<01:43, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.14G/9.98G [04:23<01:42, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.15G/9.98G [04:23<01:42, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.16G/9.98G [04:23<01:42, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.17G/9.98G [04:24<01:42, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.18G/9.98G [04:24<01:42, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.19G/9.98G [04:24<01:41, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.20G/9.98G [04:25<01:40, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.21G/9.98G [04:25<01:40, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.22G/9.98G [04:26<01:39, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.24G/9.98G [04:26<01:39, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.25G/9.98G [04:26<01:39, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.26G/9.98G [04:27<01:41, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.27G/9.98G [04:27<01:38, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.28G/9.98G [04:27<01:37, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.29G/9.98G [04:28<01:37, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.30G/9.98G [04:28<01:37, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.31G/9.98G [04:29<01:37, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.32G/9.98G [04:29<01:36, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.33G/9.98G [04:29<01:36, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.34G/9.98G [04:30<01:36, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.35G/9.98G [04:30<01:35, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.36G/9.98G [04:31<01:35, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.37G/9.98G [04:31<01:35, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.38G/9.98G [04:31<01:34, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.39G/9.98G [04:32<01:34, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.40G/9.98G [04:32<01:33, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.41G/9.98G [04:32<01:33, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.42G/9.98G [04:33<01:33, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.43G/9.98G [04:33<01:32, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.44G/9.98G [04:34<01:32, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.46G/9.98G [04:34<01:31, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.47G/9.98G [04:34<01:31, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.48G/9.98G [04:35<01:32, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.49G/9.98G [04:35<01:32, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.50G/9.98G [04:36<01:31, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.51G/9.98G [04:36<01:30, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.52G/9.98G [04:36<01:29, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.53G/9.98G [04:37<01:29, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.54G/9.98G [04:37<01:28, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.55G/9.98G [04:37<01:28, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.56G/9.98G [04:38<01:27, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.57G/9.98G [04:38<01:27, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.58G/9.98G [04:39<01:26, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.59G/9.98G [04:39<01:27, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [04:39<01:26, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.61G/9.98G [04:40<01:25, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.62G/9.98G [04:40<01:24, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.63G/9.98G [04:40<01:24, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.64G/9.98G [04:41<01:24, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.65G/9.98G [04:41<01:24, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.67G/9.98G [04:42<01:23, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.68G/9.98G [04:42<01:32, 24.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.69G/9.98G [04:42<01:20, 28.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.70G/9.98G [04:43<01:20, 28.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.71G/9.98G [04:43<01:20, 28.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.72G/9.98G [04:44<01:20, 28.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.73G/9.98G [04:44<01:21, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.74G/9.98G [04:44<01:21, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.75G/9.98G [04:45<01:21, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.76G/9.98G [04:45<01:21, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.77G/9.98G [04:45<01:20, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.78G/9.98G [04:46<01:20, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.79G/9.98G [04:46<01:19, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.80G/9.98G [04:47<01:18, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.81G/9.98G [04:47<01:19, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.82G/9.98G [04:47<01:18, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.83G/9.98G [04:48<01:18, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.84G/9.98G [04:48<01:18, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.85G/9.98G [04:49<01:17, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.86G/9.98G [04:49<01:17, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.87G/9.98G [04:49<01:19, 26.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.89G/9.98G [04:50<01:15, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.90G/9.98G [04:50<01:15, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.91G/9.98G [04:51<01:20, 25.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.92G/9.98G [04:51<01:13, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.93G/9.98G [04:51<01:13, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.94G/9.98G [04:52<01:14, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [04:52<01:13, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.96G/9.98G [04:52<01:13, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.97G/9.98G [04:53<01:12, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.98G/9.98G [04:53<01:12, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.99G/9.98G [04:54<01:12, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 8.00G/9.98G [04:54<01:12, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 8.01G/9.98G [04:54<01:11, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 8.02G/9.98G [04:55<01:11, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.03G/9.98G [04:55<01:10, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.04G/9.98G [04:55<01:10, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.05G/9.98G [04:56<01:09, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.06G/9.98G [04:56<01:09, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.07G/9.98G [04:57<01:09, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.08G/9.98G [04:57<01:08, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.10G/9.98G [04:57<01:08, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.11G/9.98G [04:58<01:08, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.12G/9.98G [04:58<01:07, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.13G/9.98G [04:58<01:07, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.14G/9.98G [04:59<01:07, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.15G/9.98G [04:59<01:06, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.16G/9.98G [05:00<01:06, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.17G/9.98G [05:00<01:05, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.18G/9.98G [05:00<01:05, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.19G/9.98G [05:01<01:05, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.20G/9.98G [05:01<01:04, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.21G/9.98G [05:02<01:04, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.22G/9.98G [05:02<01:04, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.23G/9.98G [05:02<01:04, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.24G/9.98G [05:03<01:03, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.25G/9.98G [05:03<01:02, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.26G/9.98G [05:03<01:02, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.27G/9.98G [05:04<01:01, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.28G/9.98G [05:04<01:01, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.29G/9.98G [05:05<01:01, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.30G/9.98G [05:05<01:01, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.32G/9.98G [05:05<01:00, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.33G/9.98G [05:06<01:00, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.34G/9.98G [05:06<00:59, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.35G/9.98G [05:07<00:59, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.36G/9.98G [05:07<00:59, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.37G/9.98G [05:07<00:58, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.38G/9.98G [05:08<00:58, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.39G/9.98G [05:08<00:58, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.40G/9.98G [05:08<00:56, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.41G/9.98G [05:09<00:56, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.42G/9.98G [05:09<00:56, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.43G/9.98G [05:10<00:56, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.44G/9.98G [05:10<00:55, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.45G/9.98G [05:10<00:55, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.46G/9.98G [05:11<00:55, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.47G/9.98G [05:11<00:55, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [05:11<00:54, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.49G/9.98G [05:12<00:54, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.50G/9.98G [05:12<00:53, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.51G/9.98G [05:13<00:53, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.52G/9.98G [05:13<00:53, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.54G/9.98G [05:13<00:52, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.55G/9.98G [05:14<00:52, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.56G/9.98G [05:14<00:52, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.57G/9.98G [05:15<00:51, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.58G/9.98G [05:15<00:50, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.59G/9.98G [05:15<00:50, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.60G/9.98G [05:16<00:50, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.61G/9.98G [05:16<00:49, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.62G/9.98G [05:16<00:49, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.63G/9.98G [05:17<00:49, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.64G/9.98G [05:17<00:48, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.65G/9.98G [05:18<00:48, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.66G/9.98G [05:18<00:48, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.67G/9.98G [05:18<00:47, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.68G/9.98G [05:19<00:47, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.69G/9.98G [05:19<00:46, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [05:20<00:46, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.71G/9.98G [05:20<00:46, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.72G/9.98G [05:20<00:45, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.73G/9.98G [05:21<00:45, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.75G/9.98G [05:21<00:44, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.76G/9.98G [05:21<00:44, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.77G/9.98G [05:22<00:43, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.78G/9.98G [05:22<00:43, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.79G/9.98G [05:23<00:43, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.80G/9.98G [05:23<00:42, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.81G/9.98G [05:23<00:42, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.82G/9.98G [05:24<00:42, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.83G/9.98G [05:24<00:41, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.84G/9.98G [05:24<00:41, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.85G/9.98G [05:25<00:41, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.86G/9.98G [05:25<00:40, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.87G/9.98G [05:26<00:40, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.88G/9.98G [05:26<00:40, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.89G/9.98G [05:26<00:40, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.90G/9.98G [05:27<00:39, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.91G/9.98G [05:27<00:38, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.92G/9.98G [05:28<00:39, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.93G/9.98G [05:28<00:38, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.94G/9.98G [05:28<00:37, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.95G/9.98G [05:29<00:38, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.97G/9.98G [05:29<00:36, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.98G/9.98G [05:29<00:36, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.99G/9.98G [05:30<00:35, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 9.00G/9.98G [05:30<00:35, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 9.01G/9.98G [05:31<00:35, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 9.02G/9.98G [05:31<00:35, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 9.03G/9.98G [05:31<00:34, 27.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.04G/9.98G [05:32<00:33, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [05:32<00:33, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.06G/9.98G [05:33<00:33, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.07G/9.98G [05:33<00:32, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.08G/9.98G [05:33<00:32, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.09G/9.98G [05:34<00:33, 26.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.10G/9.98G [05:34<00:31, 27.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.11G/9.98G [05:34<00:31, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.12G/9.98G [05:35<00:31, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.13G/9.98G [05:35<00:31, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.14G/9.98G [05:36<00:30, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.15G/9.98G [05:36<00:30, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.16G/9.98G [05:36<00:30, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.18G/9.98G [05:37<00:29, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.19G/9.98G [05:37<00:28, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.20G/9.98G [05:38<00:28, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.21G/9.98G [05:38<00:28, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.22G/9.98G [05:38<00:27, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.23G/9.98G [05:39<00:27, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.24G/9.98G [05:39<00:26, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.25G/9.98G [05:39<00:26, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.26G/9.98G [05:40<00:26, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.27G/9.98G [05:40<00:25, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.28G/9.98G [05:41<00:25, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.29G/9.98G [05:41<00:24, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.30G/9.98G [05:41<00:24, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.31G/9.98G [05:42<00:24, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.32G/9.98G [05:42<00:23, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.33G/9.98G [05:42<00:23, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.34G/9.98G [05:43<00:23, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.35G/9.98G [05:43<00:22, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.36G/9.98G [05:44<00:22, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.37G/9.98G [05:44<00:21, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.38G/9.98G [05:44<00:21, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.40G/9.98G [05:45<00:21, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.41G/9.98G [05:45<00:20, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.42G/9.98G [05:46<00:20, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.43G/9.98G [05:46<00:20, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.44G/9.98G [05:46<00:20, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.45G/9.98G [05:47<00:19, 27.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.46G/9.98G [05:47<00:19, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.47G/9.98G [05:47<00:18, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.48G/9.98G [05:48<00:18, 26.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.49G/9.98G [05:48<00:17, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.50G/9.98G [05:49<00:17, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.51G/9.98G [05:49<00:16, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.52G/9.98G [05:49<00:16, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.53G/9.98G [05:50<00:16, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.54G/9.98G [05:50<00:15, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [05:51<00:15, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.56G/9.98G [05:51<00:15, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.57G/9.98G [05:51<00:14, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.58G/9.98G [05:52<00:14, 26.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.59G/9.98G [05:52<00:13, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.60G/9.98G [05:52<00:13, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.62G/9.98G [05:53<00:13, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.63G/9.98G [05:53<00:12, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.64G/9.98G [05:54<00:12, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.65G/9.98G [05:54<00:12, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.66G/9.98G [05:54<00:11, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.67G/9.98G [05:55<00:11, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.68G/9.98G [05:55<00:10, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.69G/9.98G [05:56<00:10, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.70G/9.98G [05:56<00:10, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.71G/9.98G [05:56<00:09, 27.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.72G/9.98G [05:57<00:09, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.73G/9.98G [05:57<00:08, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.74G/9.98G [05:57<00:08, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.75G/9.98G [05:58<00:08, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.76G/9.98G [05:58<00:07, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.77G/9.98G [05:59<00:07, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.78G/9.98G [05:59<00:07, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.79G/9.98G [05:59<00:06, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.80G/9.98G [06:00<00:06, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.81G/9.98G [06:00<00:05, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.83G/9.98G [06:00<00:05, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [06:01<00:05, 27.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.85G/9.98G [06:01<00:04, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.86G/9.98G [06:02<00:04, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.87G/9.98G [06:02<00:03, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.88G/9.98G [06:02<00:03, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.89G/9.98G [06:03<00:03, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.90G/9.98G [06:03<00:02, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.91G/9.98G [06:04<00:02, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.92G/9.98G [06:04<00:02, 27.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin: 100% 9.93G/9.98G [06:04<00:01, 27.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin: 100% 9.94G/9.98G [06:05<00:01, 27.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin: 100% 9.95G/9.98G [06:05<00:00, 27.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin: 100% 9.96G/9.98G [06:05<00:00, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin: 100% 9.97G/9.98G [06:06<00:00, 27.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [06:06<00:00, 27.2MB/s]\n","Downloading shards:  50% 1/2 [06:07<06:07, 367.22s/it]\n","pytorch_model-00002-of-00002.bin:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   0% 10.5M/3.50G [00:00<02:10, 26.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   1% 21.0M/3.50G [00:00<02:38, 21.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   1% 31.5M/3.50G [00:01<02:22, 24.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   1% 41.9M/3.50G [00:01<02:14, 25.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   1% 52.4M/3.50G [00:02<02:28, 23.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   2% 62.9M/3.50G [00:02<02:20, 24.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   2% 73.4M/3.50G [00:03<02:17, 24.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   2% 83.9M/3.50G [00:03<02:12, 25.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   3% 94.4M/3.50G [00:03<02:21, 24.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   3% 105M/3.50G [00:04<02:14, 25.3MB/s] \u001b[A\n","pytorch_model-00002-of-00002.bin:   3% 115M/3.50G [00:04<02:10, 26.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   4% 126M/3.50G [00:04<02:06, 26.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   4% 136M/3.50G [00:05<02:04, 27.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   4% 147M/3.50G [00:05<02:02, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   4% 157M/3.50G [00:06<02:01, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   5% 168M/3.50G [00:06<02:19, 23.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   5% 178M/3.50G [00:06<01:56, 28.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   5% 189M/3.50G [00:07<01:55, 28.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   6% 199M/3.50G [00:07<01:55, 28.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   6% 210M/3.50G [00:07<01:55, 28.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   6% 220M/3.50G [00:08<01:56, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   7% 231M/3.50G [00:08<02:06, 25.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   7% 241M/3.50G [00:09<02:02, 26.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   7% 252M/3.50G [00:09<02:00, 26.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   7% 262M/3.50G [00:09<01:58, 27.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   8% 273M/3.50G [00:10<01:56, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   8% 283M/3.50G [00:10<01:55, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   8% 294M/3.50G [00:11<01:54, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   9% 304M/3.50G [00:11<01:53, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   9% 315M/3.50G [00:11<01:53, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   9% 325M/3.50G [00:12<01:52, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  10% 336M/3.50G [00:12<01:53, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  10% 346M/3.50G [00:12<01:51, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  10% 357M/3.50G [00:13<01:51, 28.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  10% 367M/3.50G [00:13<01:51, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  11% 377M/3.50G [00:14<01:50, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  11% 388M/3.50G [00:14<01:50, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  11% 398M/3.50G [00:14<01:52, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  12% 409M/3.50G [00:15<01:50, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  12% 419M/3.50G [00:15<01:50, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  12% 430M/3.50G [00:15<01:49, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  13% 440M/3.50G [00:16<01:48, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  13% 451M/3.50G [00:16<01:57, 26.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  13% 461M/3.50G [00:17<01:54, 26.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  13% 472M/3.50G [00:17<01:51, 27.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  14% 482M/3.50G [00:17<01:50, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  14% 493M/3.50G [00:18<01:48, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  14% 503M/3.50G [00:18<01:47, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  15% 514M/3.50G [00:19<01:46, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  15% 524M/3.50G [00:19<01:46, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  15% 535M/3.50G [00:19<01:47, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  16% 545M/3.50G [00:20<01:46, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  16% 556M/3.50G [00:20<01:45, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  16% 566M/3.50G [00:20<01:45, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  16% 577M/3.50G [00:21<01:44, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  17% 587M/3.50G [00:21<01:44, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  17% 598M/3.50G [00:22<01:43, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  17% 608M/3.50G [00:22<01:43, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  18% 619M/3.50G [00:22<01:42, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  18% 629M/3.50G [00:23<01:41, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  18% 640M/3.50G [00:23<01:41, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  19% 650M/3.50G [00:23<01:43, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  19% 661M/3.50G [00:24<01:39, 28.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  19% 671M/3.50G [00:24<01:46, 26.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  19% 682M/3.50G [00:25<01:44, 26.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  20% 692M/3.50G [00:25<01:42, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  20% 703M/3.50G [00:25<01:41, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  20% 713M/3.50G [00:26<01:41, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  21% 724M/3.50G [00:26<01:39, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  21% 734M/3.50G [00:26<01:39, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  21% 744M/3.50G [00:27<01:38, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  22% 755M/3.50G [00:27<01:38, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  22% 765M/3.50G [00:28<01:38, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  22% 776M/3.50G [00:28<01:40, 27.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  22% 786M/3.50G [00:28<01:38, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  23% 797M/3.50G [00:29<01:38, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  23% 807M/3.50G [00:29<01:36, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  23% 818M/3.50G [00:29<01:36, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  24% 828M/3.50G [00:30<01:35, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  24% 839M/3.50G [00:30<01:36, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  24% 849M/3.50G [00:31<01:38, 27.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  25% 860M/3.50G [00:31<01:36, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  25% 870M/3.50G [00:31<01:36, 27.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  25% 881M/3.50G [00:32<01:35, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  25% 891M/3.50G [00:32<01:34, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  26% 902M/3.50G [00:33<01:33, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  26% 912M/3.50G [00:33<01:32, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  26% 923M/3.50G [00:33<01:32, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  27% 933M/3.50G [00:34<01:31, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  27% 944M/3.50G [00:34<01:30, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  27% 954M/3.50G [00:34<01:31, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  28% 965M/3.50G [00:35<01:31, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  28% 975M/3.50G [00:35<01:30, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  28% 986M/3.50G [00:36<01:32, 27.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  28% 996M/3.50G [00:36<01:30, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  29% 1.01G/3.50G [00:36<01:29, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  29% 1.02G/3.50G [00:37<01:28, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  29% 1.03G/3.50G [00:37<01:28, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  30% 1.04G/3.50G [00:37<01:28, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  30% 1.05G/3.50G [00:38<01:28, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  30% 1.06G/3.50G [00:38<01:27, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  31% 1.07G/3.50G [00:39<01:26, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  31% 1.08G/3.50G [00:39<01:26, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  31% 1.09G/3.50G [00:39<01:25, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  31% 1.10G/3.50G [00:40<01:25, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  32% 1.11G/3.50G [00:40<01:26, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  32% 1.12G/3.50G [00:40<01:25, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  32% 1.13G/3.50G [00:41<01:25, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  33% 1.14G/3.50G [00:41<01:24, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  33% 1.15G/3.50G [00:42<01:23, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  33% 1.16G/3.50G [00:42<01:24, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  34% 1.17G/3.50G [00:42<01:29, 26.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  34% 1.18G/3.50G [00:43<01:26, 26.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  34% 1.20G/3.50G [00:43<01:26, 26.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  34% 1.21G/3.50G [00:44<01:24, 27.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  35% 1.22G/3.50G [00:44<01:23, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  35% 1.23G/3.50G [00:44<01:22, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  35% 1.24G/3.50G [00:45<01:21, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  36% 1.25G/3.50G [00:45<01:20, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  36% 1.26G/3.50G [00:45<01:19, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  36% 1.27G/3.50G [00:46<01:19, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  37% 1.28G/3.50G [00:46<01:18, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  37% 1.29G/3.50G [00:47<01:18, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  37% 1.30G/3.50G [00:47<01:18, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  37% 1.31G/3.50G [00:47<01:18, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:48<01:17, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  38% 1.33G/3.50G [00:48<01:17, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  38% 1.34G/3.50G [00:48<01:17, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  39% 1.35G/3.50G [00:49<01:16, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  39% 1.36G/3.50G [00:49<01:16, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  39% 1.37G/3.50G [00:50<01:16, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  40% 1.38G/3.50G [00:50<01:16, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  40% 1.39G/3.50G [00:50<01:17, 27.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  40% 1.41G/3.50G [00:51<01:16, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  40% 1.42G/3.50G [00:51<01:15, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  41% 1.43G/3.50G [00:51<01:15, 27.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  41% 1.44G/3.50G [00:52<01:15, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  41% 1.45G/3.50G [00:52<01:15, 27.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  42% 1.46G/3.50G [00:53<01:15, 27.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  42% 1.47G/3.50G [00:53<01:13, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [00:53<01:13, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  43% 1.49G/3.50G [00:54<01:12, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  43% 1.50G/3.50G [00:54<01:11, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  43% 1.51G/3.50G [00:54<01:10, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  43% 1.52G/3.50G [00:55<01:10, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  44% 1.53G/3.50G [00:55<01:09, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  44% 1.54G/3.50G [00:56<01:09, 28.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  44% 1.55G/3.50G [00:56<01:09, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  45% 1.56G/3.50G [00:56<01:10, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  45% 1.57G/3.50G [00:57<01:08, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  45% 1.58G/3.50G [00:57<01:08, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  46% 1.59G/3.50G [00:57<01:08, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  46% 1.60G/3.50G [00:58<01:07, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  46% 1.61G/3.50G [00:58<01:07, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  46% 1.63G/3.50G [00:59<01:06, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  47% 1.64G/3.50G [00:59<01:06, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  47% 1.65G/3.50G [00:59<01:05, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  47% 1.66G/3.50G [01:00<01:05, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  48% 1.67G/3.50G [01:00<01:05, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  48% 1.68G/3.50G [01:00<01:04, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  48% 1.69G/3.50G [01:01<01:04, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  49% 1.70G/3.50G [01:01<01:04, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  49% 1.71G/3.50G [01:02<01:03, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  49% 1.72G/3.50G [01:02<01:05, 27.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  49% 1.73G/3.50G [01:02<01:02, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  50% 1.74G/3.50G [01:03<01:03, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  50% 1.75G/3.50G [01:03<01:02, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  50% 1.76G/3.50G [01:03<01:02, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  51% 1.77G/3.50G [01:04<01:02, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  51% 1.78G/3.50G [01:04<01:01, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  51% 1.79G/3.50G [01:05<01:01, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  52% 1.80G/3.50G [01:05<01:03, 26.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  52% 1.81G/3.50G [01:05<01:01, 27.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  52% 1.82G/3.50G [01:06<01:01, 27.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  52% 1.84G/3.50G [01:06<01:01, 27.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  53% 1.85G/3.50G [01:07<01:00, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  53% 1.86G/3.50G [01:07<00:59, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  53% 1.87G/3.50G [01:07<00:58, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  54% 1.88G/3.50G [01:08<00:58, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  54% 1.89G/3.50G [01:08<00:57, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  54% 1.90G/3.50G [01:08<00:56, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  55% 1.91G/3.50G [01:09<00:56, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  55% 1.92G/3.50G [01:09<00:56, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  55% 1.93G/3.50G [01:10<00:55, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  55% 1.94G/3.50G [01:10<00:55, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  56% 1.95G/3.50G [01:10<00:55, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  56% 1.96G/3.50G [01:11<00:54, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  56% 1.97G/3.50G [01:11<00:54, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  57% 1.98G/3.50G [01:11<00:53, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  57% 1.99G/3.50G [01:12<00:53, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  57% 2.00G/3.50G [01:12<00:54, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  58% 2.01G/3.50G [01:12<00:53, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  58% 2.02G/3.50G [01:13<00:52, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  58% 2.03G/3.50G [01:13<00:52, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  58% 2.04G/3.50G [01:14<00:51, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  59% 2.06G/3.50G [01:14<00:51, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  59% 2.07G/3.50G [01:14<00:50, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  59% 2.08G/3.50G [01:15<00:50, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  60% 2.09G/3.50G [01:15<00:50, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  60% 2.10G/3.50G [01:15<00:50, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  60% 2.11G/3.50G [01:16<00:49, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  61% 2.12G/3.50G [01:16<00:50, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  61% 2.13G/3.50G [01:17<00:49, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  61% 2.14G/3.50G [01:17<00:49, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  61% 2.15G/3.50G [01:17<00:49, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  62% 2.16G/3.50G [01:18<00:48, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  62% 2.17G/3.50G [01:18<00:47, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  62% 2.18G/3.50G [01:19<00:47, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  63% 2.19G/3.50G [01:19<00:47, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  63% 2.20G/3.50G [01:19<00:47, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  63% 2.21G/3.50G [01:20<00:46, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  64% 2.22G/3.50G [01:20<00:46, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  64% 2.23G/3.50G [01:20<00:45, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  64% 2.24G/3.50G [01:21<00:44, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  64% 2.25G/3.50G [01:21<00:44, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  65% 2.26G/3.50G [01:22<00:43, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  65% 2.28G/3.50G [01:22<00:43, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  65% 2.29G/3.50G [01:22<00:43, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  66% 2.30G/3.50G [01:23<00:42, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  66% 2.31G/3.50G [01:23<00:42, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  66% 2.32G/3.50G [01:23<00:41, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  67% 2.33G/3.50G [01:24<00:41, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  67% 2.34G/3.50G [01:24<00:41, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  67% 2.35G/3.50G [01:25<00:41, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  67% 2.36G/3.50G [01:25<00:40, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  68% 2.37G/3.50G [01:25<00:40, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  68% 2.38G/3.50G [01:26<00:40, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  68% 2.39G/3.50G [01:26<00:39, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  69% 2.40G/3.50G [01:26<00:40, 27.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  69% 2.41G/3.50G [01:27<00:39, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  69% 2.42G/3.50G [01:27<00:38, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  69% 2.43G/3.50G [01:28<00:38, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  70% 2.44G/3.50G [01:28<00:39, 27.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  70% 2.45G/3.50G [01:28<00:37, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  70% 2.46G/3.50G [01:29<00:36, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  71% 2.47G/3.50G [01:29<00:36, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  71% 2.49G/3.50G [01:29<00:36, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  71% 2.50G/3.50G [01:30<00:35, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  72% 2.51G/3.50G [01:30<00:35, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  72% 2.52G/3.50G [01:31<00:35, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  72% 2.53G/3.50G [01:31<00:34, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  72% 2.54G/3.50G [01:31<00:34, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  73% 2.55G/3.50G [01:32<00:34, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  73% 2.56G/3.50G [01:32<00:34, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  73% 2.57G/3.50G [01:32<00:33, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  74% 2.58G/3.50G [01:33<00:33, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  74% 2.59G/3.50G [01:33<00:32, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  74% 2.60G/3.50G [01:34<00:32, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  75% 2.61G/3.50G [01:34<00:31, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  75% 2.62G/3.50G [01:34<00:31, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  75% 2.63G/3.50G [01:35<00:31, 27.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  75% 2.64G/3.50G [01:35<00:30, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  76% 2.65G/3.50G [01:35<00:30, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  76% 2.66G/3.50G [01:36<00:30, 27.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  76% 2.67G/3.50G [01:36<00:29, 28.4MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  77% 2.68G/3.50G [01:37<00:29, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  77% 2.69G/3.50G [01:37<00:28, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  77% 2.71G/3.50G [01:37<00:28, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  78% 2.72G/3.50G [01:38<00:28, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  78% 2.73G/3.50G [01:38<00:27, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  78% 2.74G/3.50G [01:38<00:27, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  78% 2.75G/3.50G [01:39<00:27, 27.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  79% 2.76G/3.50G [01:39<00:27, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  79% 2.77G/3.50G [01:40<00:26, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  79% 2.78G/3.50G [01:40<00:26, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  80% 2.79G/3.50G [01:40<00:26, 27.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  80% 2.80G/3.50G [01:41<00:25, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  80% 2.81G/3.50G [01:41<00:24, 28.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  81% 2.82G/3.50G [01:41<00:24, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  81% 2.83G/3.50G [01:42<00:23, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  81% 2.84G/3.50G [01:42<00:23, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  81% 2.85G/3.50G [01:43<00:23, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  82% 2.86G/3.50G [01:43<00:22, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  82% 2.87G/3.50G [01:43<00:22, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  82% 2.88G/3.50G [01:44<00:21, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  83% 2.89G/3.50G [01:44<00:21, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  83% 2.90G/3.50G [01:44<00:21, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  83% 2.92G/3.50G [01:45<00:20, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  84% 2.93G/3.50G [01:45<00:20, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  84% 2.94G/3.50G [01:46<00:20, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  84% 2.95G/3.50G [01:46<00:19, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  84% 2.96G/3.50G [01:46<00:19, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  85% 2.97G/3.50G [01:47<00:18, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  85% 2.98G/3.50G [01:47<00:18, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  85% 2.99G/3.50G [01:47<00:18, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  86% 3.00G/3.50G [01:48<00:20, 24.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  86% 3.01G/3.50G [01:48<00:17, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  86% 3.02G/3.50G [01:49<00:17, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  87% 3.03G/3.50G [01:49<00:17, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  87% 3.04G/3.50G [01:49<00:16, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  87% 3.05G/3.50G [01:50<00:16, 27.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  87% 3.06G/3.50G [01:50<00:16, 27.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  88% 3.07G/3.50G [01:51<00:15, 27.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  88% 3.08G/3.50G [01:51<00:15, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  88% 3.09G/3.50G [01:51<00:14, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  89% 3.10G/3.50G [01:52<00:14, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  89% 3.11G/3.50G [01:52<00:13, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  89% 3.12G/3.50G [01:52<00:13, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  90% 3.14G/3.50G [01:53<00:12, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  90% 3.15G/3.50G [01:53<00:12, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  90% 3.16G/3.50G [01:54<00:12, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  90% 3.17G/3.50G [01:54<00:11, 28.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  91% 3.18G/3.50G [01:54<00:11, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  91% 3.19G/3.50G [01:55<00:11, 28.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  91% 3.20G/3.50G [01:55<00:10, 28.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  92% 3.21G/3.50G [01:55<00:10, 28.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  92% 3.22G/3.50G [01:56<00:09, 28.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  92% 3.23G/3.50G [01:56<00:09, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  93% 3.24G/3.50G [01:57<00:09, 27.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  93% 3.25G/3.50G [01:57<00:09, 27.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  93% 3.26G/3.50G [01:57<00:08, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  93% 3.27G/3.50G [01:58<00:08, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  94% 3.28G/3.50G [01:58<00:07, 27.5MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  94% 3.29G/3.50G [01:58<00:07, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  94% 3.30G/3.50G [01:59<00:07, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  95% 3.31G/3.50G [01:59<00:06, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  95% 3.32G/3.50G [02:00<00:06, 27.7MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  95% 3.33G/3.50G [02:00<00:05, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  96% 3.34G/3.50G [02:00<00:05, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  96% 3.36G/3.50G [02:01<00:05, 27.3MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  96% 3.37G/3.50G [02:01<00:04, 27.6MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  96% 3.38G/3.50G [02:01<00:04, 27.8MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  97% 3.39G/3.50G [02:02<00:04, 27.9MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  97% 3.40G/3.50G [02:02<00:03, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  97% 3.41G/3.50G [02:03<00:03, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  98% 3.42G/3.50G [02:03<00:02, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  98% 3.43G/3.50G [02:03<00:02, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  98% 3.44G/3.50G [02:04<00:02, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  99% 3.45G/3.50G [02:04<00:01, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  99% 3.46G/3.50G [02:04<00:01, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  99% 3.47G/3.50G [02:05<00:01, 28.1MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  99% 3.48G/3.50G [02:05<00:00, 28.2MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin: 100% 3.49G/3.50G [02:06<00:00, 28.0MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [02:06<00:00, 27.7MB/s]\n","Downloading shards: 100% 2/2 [08:14<00:00, 247.07s/it]\n","Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.30s/it]\n","generation_config.json: 100% 132/132 [00:00<00:00, 782kB/s]\n","tokenizer_config.json: 100% 776/776 [00:00<00:00, 3.95MB/s]\n","tokenizer.model: 100% 500k/500k [00:00<00:00, 176MB/s]\n","tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 3.30MB/s]\n","special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.53MB/s]\n","2024-03-19:11:39:39,155 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","Downloading builder script: 100% 28.3k/28.3k [00:00<00:00, 56.3MB/s]\n","Downloading readme: 100% 26.6k/26.6k [00:00<00:00, 55.7MB/s]\n","Downloading data: 854kB [00:00, 7.79MB/s]\n","Downloading data: 182kB [00:00, 4.04MB/s]        \n","Downloading data: 182kB [00:00, 4.07MB/s]        \n","Generating train split: 100% 6078/6078 [00:00<00:00, 28937.04 examples/s]\n","Generating test split: 100% 1302/1302 [00:00<00:00, 29904.36 examples/s]\n","Generating validation split: 100% 1302/1302 [00:00<00:00, 30953.75 examples/s]\n","2024-03-19:11:39:47,587 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt4 from None to 5\n","2024-03-19:11:39:47,588 INFO     [task.py:386] Building contexts for prompt4 on rank 0...\n","100% 1302/1302 [00:06<00:00, 211.07it/s]\n","2024-03-19:11:39:53,791 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [49:10<00:00,  1.32it/s]\n","hf (pretrained=HiTZ/latxa-7b-v1), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt4|Yaml   |none  |     5|acc   |0.4823|±  |0.0139|\n","\n"]}]},{"cell_type":"code","source":["files.download('pretrained__HiTZ__latxa-7b-v1_prompt4.jsonl')\n","files.download('prompt4_latxa.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"mwzRo600dVtX","executionInfo":{"status":"ok","timestamp":1710852276206,"user_tz":-60,"elapsed":571,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"e5f9946d-1fb7-4e8d-af44-c8d5a37a8446"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_fa4584db-13e3-4695-aff9-5bb28153a128\", \"pretrained__HiTZ__latxa-7b-v1_prompt4.jsonl\", 6301203)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_1897199e-68be-4682-828c-a3b1755d6091\", \"prompt4_latxa.json\", 5414)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Prompt 5"],"metadata":{"id":"YgMV6XEydJmu"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=HiTZ/latxa-7b-v1 \\\n","    --tasks prompt5 \\\n","    --device cuda \\\n","    --output_path ./prompt5_latxa.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"id":"CuaYSBmddM46","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710859655965,"user_tz":-60,"elapsed":2837604,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"c6f1dd1a-f5f9-4a57-9c9b-d5cdc0b93bf4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-19 14:00:21.216202: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-19 14:00:21.216254: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-19 14:00:21.217552: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-19 14:00:22.428586: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-19:14:00:26,175 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-19:14:00:26,175 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-19:14:00:31,796 INFO     [__main__.py:293] Selected Tasks: ['prompt5']\n","2024-03-19:14:00:31,797 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-19:14:00:31,798 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-19:14:00:31,845 INFO     [huggingface.py:162] Using device 'cuda'\n","config.json: 100% 601/601 [00:00<00:00, 2.79MB/s]\n","pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 73.8MB/s]\n","Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n","pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   0% 10.5M/9.98G [00:00<01:54, 86.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   0% 31.5M/9.98G [00:00<01:07, 148MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 73.4M/9.98G [00:00<00:44, 225MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   1% 115M/9.98G [00:00<00:36, 270MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 157M/9.98G [00:00<00:32, 306MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 199M/9.98G [00:00<00:29, 331MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   2% 241M/9.98G [00:00<00:27, 350MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 283M/9.98G [00:00<00:26, 364MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   3% 325M/9.98G [00:01<00:26, 371MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 367M/9.98G [00:01<00:25, 375MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   4% 409M/9.98G [00:01<00:25, 382MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 451M/9.98G [00:01<00:24, 386MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 493M/9.98G [00:01<00:24, 388MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   5% 535M/9.98G [00:01<00:24, 387MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 577M/9.98G [00:01<00:25, 363MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   6% 619M/9.98G [00:01<00:26, 356MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 661M/9.98G [00:01<00:25, 362MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 703M/9.98G [00:02<00:25, 363MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   7% 744M/9.98G [00:02<00:26, 354MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 786M/9.98G [00:02<00:26, 352MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   8% 828M/9.98G [00:02<00:25, 356MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 870M/9.98G [00:02<00:26, 342MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:   9% 912M/9.98G [00:02<00:26, 336MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 954M/9.98G [00:02<00:27, 332MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 996M/9.98G [00:02<00:26, 339MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  10% 1.04G/9.98G [00:03<00:25, 349MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:03<00:24, 369MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  11% 1.13G/9.98G [00:03<00:24, 367MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.17G/9.98G [00:03<00:23, 375MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  12% 1.22G/9.98G [00:03<00:23, 368MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.26G/9.98G [00:03<00:23, 375MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.30G/9.98G [00:03<00:23, 375MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  13% 1.34G/9.98G [00:03<00:22, 377MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.38G/9.98G [00:03<00:22, 382MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  14% 1.43G/9.98G [00:04<00:22, 385MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.47G/9.98G [00:04<00:21, 388MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  15% 1.51G/9.98G [00:04<00:23, 354MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.55G/9.98G [00:04<00:32, 263MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.58G/9.98G [00:04<00:34, 241MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  16% 1.61G/9.98G [00:04<00:34, 241MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.66G/9.98G [00:04<00:30, 276MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.70G/9.98G [00:05<00:28, 295MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  17% 1.74G/9.98G [00:05<00:26, 307MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.78G/9.98G [00:05<00:27, 294MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  18% 1.82G/9.98G [00:05<00:26, 311MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [00:05<00:24, 330MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  19% 1.91G/9.98G [00:05<00:23, 345MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 1.95G/9.98G [00:05<00:22, 352MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 1.99G/9.98G [00:05<00:21, 365MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  20% 2.03G/9.98G [00:06<00:21, 374MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.08G/9.98G [00:06<00:20, 381MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  21% 2.12G/9.98G [00:06<00:21, 372MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [00:06<00:22, 346MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.20G/9.98G [00:06<00:24, 324MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  22% 2.24G/9.98G [00:06<00:24, 317MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.29G/9.98G [00:06<00:23, 327MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  23% 2.33G/9.98G [00:06<00:23, 324MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.37G/9.98G [00:07<00:23, 329MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  24% 2.41G/9.98G [00:07<00:23, 322MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.45G/9.98G [00:07<00:22, 331MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.50G/9.98G [00:07<00:22, 333MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  25% 2.54G/9.98G [00:07<00:22, 331MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.58G/9.98G [00:07<00:22, 329MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  26% 2.62G/9.98G [00:07<00:22, 326MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.66G/9.98G [00:07<00:21, 333MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  27% 2.71G/9.98G [00:08<00:21, 345MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [00:08<00:20, 359MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.79G/9.98G [00:08<00:19, 369MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  28% 2.83G/9.98G [00:08<00:19, 374MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.87G/9.98G [00:08<00:18, 379MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  29% 2.92G/9.98G [00:08<00:18, 383MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 2.96G/9.98G [00:08<00:18, 385MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 3.00G/9.98G [00:08<00:18, 386MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  30% 3.04G/9.98G [00:08<00:18, 383MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.08G/9.98G [00:09<00:18, 382MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  31% 3.12G/9.98G [00:09<00:17, 385MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.17G/9.98G [00:09<00:17, 387MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  32% 3.21G/9.98G [00:09<00:17, 389MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.25G/9.98G [00:09<00:17, 387MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.29G/9.98G [00:09<00:17, 384MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  33% 3.33G/9.98G [00:09<00:17, 378MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.38G/9.98G [00:09<00:17, 371MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  34% 3.42G/9.98G [00:09<00:17, 365MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.46G/9.98G [00:10<00:18, 359MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.50G/9.98G [00:10<00:27, 239MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  35% 3.53G/9.98G [00:10<00:40, 161MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.57G/9.98G [00:10<00:42, 149MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.59G/9.98G [00:11<00:51, 125MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.61G/9.98G [00:11<00:54, 117MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  36% 3.63G/9.98G [00:11<00:53, 118MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.65G/9.98G [00:11<01:03, 100MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.67G/9.98G [00:12<01:10, 89.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.68G/9.98G [00:12<01:16, 82.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.69G/9.98G [00:12<01:20, 78.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [00:12<01:22, 75.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.71G/9.98G [00:12<01:24, 74.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  37% 3.72G/9.98G [00:13<01:30, 68.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.75G/9.98G [00:13<01:06, 93.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.76G/9.98G [00:13<01:08, 90.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.77G/9.98G [00:13<01:13, 84.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.79G/9.98G [00:13<01:17, 79.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.80G/9.98G [00:13<01:29, 69.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.81G/9.98G [00:14<01:29, 69.2MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.82G/9.98G [00:14<01:27, 70.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.83G/9.98G [00:14<01:32, 66.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  38% 3.84G/9.98G [00:14<01:25, 71.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.85G/9.98G [00:14<01:34, 64.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.87G/9.98G [00:14<01:05, 92.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.89G/9.98G [00:15<01:02, 97.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  39% 3.92G/9.98G [00:15<00:43, 139MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.94G/9.98G [00:15<00:47, 126MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.96G/9.98G [00:15<00:57, 105MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 3.98G/9.98G [00:15<01:07, 88.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 4.01G/9.98G [00:16<01:12, 82.5MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  40% 4.02G/9.98G [00:16<01:16, 77.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.06G/9.98G [00:16<00:46, 129MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  41% 4.10G/9.98G [00:16<00:33, 177MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.14G/9.98G [00:16<00:26, 220MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.17G/9.98G [00:16<00:25, 232MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  42% 4.20G/9.98G [00:17<00:23, 247MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.25G/9.98G [00:17<00:20, 280MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.29G/9.98G [00:17<00:19, 298MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  43% 4.33G/9.98G [00:17<00:18, 310MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.37G/9.98G [00:17<00:19, 290MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  44% 4.41G/9.98G [00:17<00:17, 310MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.46G/9.98G [00:17<00:17, 320MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  45% 4.50G/9.98G [00:17<00:16, 330MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.54G/9.98G [00:18<00:16, 338MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.58G/9.98G [00:18<00:15, 344MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  46% 4.62G/9.98G [00:18<00:15, 353MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.67G/9.98G [00:18<00:14, 364MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  47% 4.71G/9.98G [00:18<00:14, 371MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.75G/9.98G [00:18<00:14, 369MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.79G/9.98G [00:18<00:13, 371MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  48% 4.83G/9.98G [00:18<00:13, 372MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.88G/9.98G [00:18<00:13, 375MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  49% 4.92G/9.98G [00:19<00:13, 377MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 4.96G/9.98G [00:19<00:13, 379MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  50% 5.00G/9.98G [00:19<00:13, 382MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.04G/9.98G [00:19<00:12, 383MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.09G/9.98G [00:19<00:12, 382MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  51% 5.13G/9.98G [00:19<00:12, 381MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.17G/9.98G [00:19<00:12, 382MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  52% 5.21G/9.98G [00:19<00:12, 380MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.25G/9.98G [00:19<00:12, 383MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.30G/9.98G [00:20<00:12, 387MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  53% 5.34G/9.98G [00:20<00:12, 383MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.38G/9.98G [00:20<00:12, 379MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  54% 5.42G/9.98G [00:20<00:11, 386MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.46G/9.98G [00:20<00:11, 379MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  55% 5.51G/9.98G [00:20<00:12, 365MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.55G/9.98G [00:20<00:12, 361MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.59G/9.98G [00:20<00:13, 327MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  56% 5.63G/9.98G [00:20<00:12, 335MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.67G/9.98G [00:21<00:12, 337MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  57% 5.71G/9.98G [00:21<00:12, 349MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.76G/9.98G [00:21<00:11, 355MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  58% 5.80G/9.98G [00:21<00:11, 360MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.84G/9.98G [00:21<00:11, 361MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.88G/9.98G [00:21<00:11, 360MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  59% 5.92G/9.98G [00:21<00:11, 363MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 5.97G/9.98G [00:21<00:11, 363MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  60% 6.01G/9.98G [00:22<00:10, 361MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.05G/9.98G [00:22<00:10, 363MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.09G/9.98G [00:22<00:10, 363MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  61% 6.13G/9.98G [00:22<00:10, 365MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.18G/9.98G [00:22<00:10, 363MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  62% 6.22G/9.98G [00:22<00:10, 351MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.26G/9.98G [00:22<00:11, 329MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.30G/9.98G [00:23<00:17, 205MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  63% 6.33G/9.98G [00:23<00:16, 216MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.36G/9.98G [00:23<00:15, 230MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.40G/9.98G [00:23<00:14, 244MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  64% 6.43G/9.98G [00:23<00:13, 259MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.47G/9.98G [00:23<00:12, 286MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  65% 6.51G/9.98G [00:23<00:11, 314MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.56G/9.98G [00:23<00:09, 345MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  66% 6.61G/9.98G [00:24<00:09, 358MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.65G/9.98G [00:24<00:09, 369MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.69G/9.98G [00:24<00:08, 375MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  67% 6.73G/9.98G [00:24<00:08, 383MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.77G/9.98G [00:24<00:08, 391MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  68% 6.82G/9.98G [00:24<00:08, 394MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.86G/9.98G [00:24<00:07, 397MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  69% 6.90G/9.98G [00:24<00:07, 396MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.94G/9.98G [00:24<00:07, 381MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 6.98G/9.98G [00:24<00:08, 372MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  70% 7.03G/9.98G [00:25<00:08, 365MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.07G/9.98G [00:25<00:07, 365MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  71% 7.11G/9.98G [00:25<00:07, 370MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.15G/9.98G [00:25<00:07, 380MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  72% 7.19G/9.98G [00:25<00:07, 380MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.24G/9.98G [00:25<00:07, 370MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.28G/9.98G [00:25<00:07, 369MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  73% 7.32G/9.98G [00:25<00:07, 358MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.36G/9.98G [00:26<00:07, 343MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  74% 7.40G/9.98G [00:26<00:07, 334MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.44G/9.98G [00:26<00:07, 340MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.49G/9.98G [00:26<00:07, 340MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  75% 7.53G/9.98G [00:26<00:08, 298MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.56G/9.98G [00:27<00:14, 164MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [00:27<00:12, 196MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.63G/9.98G [00:27<00:10, 214MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.67G/9.98G [00:27<00:10, 225MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  77% 7.71G/9.98G [00:27<00:08, 259MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.75G/9.98G [00:27<00:07, 290MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  78% 7.79G/9.98G [00:27<00:07, 312MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.83G/9.98G [00:27<00:06, 323MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.87G/9.98G [00:28<00:15, 136MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.91G/9.98G [00:28<00:16, 123MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  79% 7.93G/9.98G [00:29<00:16, 127MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [00:29<00:18, 112MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.97G/9.98G [00:29<00:19, 102MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 7.99G/9.98G [00:29<00:22, 89.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 8.01G/9.98G [00:30<00:24, 78.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  80% 8.02G/9.98G [00:30<00:24, 79.4MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.03G/9.98G [00:30<00:25, 75.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.04G/9.98G [00:30<00:25, 75.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.05G/9.98G [00:30<00:26, 72.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.06G/9.98G [00:31<00:27, 70.7MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.07G/9.98G [00:31<00:27, 69.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.08G/9.98G [00:31<00:27, 68.0MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.12G/9.98G [00:31<00:18, 101MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  81% 8.13G/9.98G [00:31<00:20, 90.9MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.15G/9.98G [00:31<00:20, 89.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.17G/9.98G [00:32<00:18, 98.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.18G/9.98G [00:32<00:18, 95.3MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.20G/9.98G [00:32<00:15, 115MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  82% 8.22G/9.98G [00:32<00:15, 111MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.24G/9.98G [00:32<00:13, 125MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.26G/9.98G [00:32<00:16, 103MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.28G/9.98G [00:33<00:19, 85.1MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.29G/9.98G [00:33<00:20, 81.8MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  83% 8.30G/9.98G [00:33<00:20, 81.6MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.34G/9.98G [00:33<00:13, 123MB/s] \u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.37G/9.98G [00:33<00:10, 158MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  84% 8.41G/9.98G [00:33<00:07, 202MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.45G/9.98G [00:34<00:06, 241MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  85% 8.49G/9.98G [00:34<00:05, 267MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.54G/9.98G [00:34<00:05, 284MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.58G/9.98G [00:34<00:04, 303MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  86% 8.62G/9.98G [00:34<00:04, 313MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.66G/9.98G [00:34<00:04, 312MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [00:34<00:04, 313MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.75G/9.98G [00:34<00:03, 318MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.79G/9.98G [00:35<00:03, 316MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  88% 8.83G/9.98G [00:35<00:03, 300MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.87G/9.98G [00:35<00:03, 310MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  89% 8.90G/9.98G [00:35<00:03, 300MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.93G/9.98G [00:35<00:03, 301MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 8.97G/9.98G [00:35<00:03, 303MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  90% 9.01G/9.98G [00:35<00:03, 315MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [00:35<00:02, 315MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.09G/9.98G [00:36<00:03, 280MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  91% 9.12G/9.98G [00:36<00:03, 274MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.15G/9.98G [00:36<00:03, 272MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.19G/9.98G [00:36<00:02, 278MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  92% 9.22G/9.98G [00:36<00:02, 284MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.25G/9.98G [00:36<00:02, 290MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  93% 9.29G/9.98G [00:36<00:02, 303MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.33G/9.98G [00:36<00:02, 322MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.37G/9.98G [00:37<00:01, 341MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  94% 9.42G/9.98G [00:37<00:01, 357MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.46G/9.98G [00:37<00:01, 354MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  95% 9.50G/9.98G [00:37<00:01, 360MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.54G/9.98G [00:37<00:01, 355MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.58G/9.98G [00:37<00:01, 355MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  96% 9.63G/9.98G [00:37<00:00, 364MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.67G/9.98G [00:37<00:00, 365MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  97% 9.71G/9.98G [00:37<00:00, 365MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.75G/9.98G [00:38<00:00, 369MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  98% 9.79G/9.98G [00:38<00:00, 242MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [00:38<00:00, 268MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.88G/9.98G [00:38<00:00, 294MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin:  99% 9.92G/9.98G [00:38<00:00, 321MB/s]\u001b[A\n","pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [00:38<00:00, 257MB/s]\n","Downloading shards:  50% 1/2 [00:39<00:39, 39.28s/it]\n","pytorch_model-00002-of-00002.bin:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   1% 21.0M/3.50G [00:00<00:21, 165MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   1% 52.4M/3.50G [00:00<00:15, 224MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   2% 83.9M/3.50G [00:00<00:13, 252MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   3% 115M/3.50G [00:00<00:12, 264MB/s] \u001b[A\n","pytorch_model-00002-of-00002.bin:   4% 147M/3.50G [00:00<00:11, 279MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   5% 189M/3.50G [00:00<00:11, 299MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   7% 231M/3.50G [00:00<00:10, 321MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   8% 273M/3.50G [00:00<00:09, 345MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:   9% 315M/3.50G [00:01<00:09, 352MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  10% 357M/3.50G [00:01<00:08, 352MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  11% 398M/3.50G [00:01<00:08, 345MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  13% 440M/3.50G [00:01<00:09, 327MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  14% 482M/3.50G [00:01<00:09, 331MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  15% 524M/3.50G [00:01<00:09, 326MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  16% 566M/3.50G [00:01<00:09, 318MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  17% 608M/3.50G [00:01<00:08, 328MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  19% 650M/3.50G [00:02<00:08, 325MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  20% 692M/3.50G [00:02<00:08, 322MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  21% 734M/3.50G [00:02<00:08, 314MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  22% 776M/3.50G [00:02<00:08, 337MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  23% 818M/3.50G [00:02<00:11, 232MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  25% 860M/3.50G [00:02<00:10, 263MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  26% 902M/3.50G [00:02<00:08, 293MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  27% 944M/3.50G [00:03<00:08, 312MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  28% 986M/3.50G [00:03<00:07, 330MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  29% 1.03G/3.50G [00:03<00:07, 342MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  31% 1.07G/3.50G [00:03<00:06, 356MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  32% 1.11G/3.50G [00:03<00:06, 364MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  33% 1.15G/3.50G [00:03<00:06, 342MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  34% 1.20G/3.50G [00:03<00:07, 329MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  35% 1.24G/3.50G [00:03<00:07, 316MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  37% 1.28G/3.50G [00:04<00:07, 308MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:04<00:06, 316MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  39% 1.36G/3.50G [00:04<00:06, 313MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  40% 1.41G/3.50G [00:04<00:06, 308MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  41% 1.45G/3.50G [00:04<00:07, 290MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [00:04<00:06, 293MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  43% 1.52G/3.50G [00:04<00:06, 308MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  45% 1.56G/3.50G [00:04<00:06, 320MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  46% 1.60G/3.50G [00:05<00:05, 328MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  47% 1.65G/3.50G [00:05<00:05, 327MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  48% 1.69G/3.50G [00:05<00:05, 333MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  49% 1.73G/3.50G [00:05<00:05, 322MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  51% 1.77G/3.50G [00:05<00:05, 305MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  52% 1.80G/3.50G [00:05<00:05, 300MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  52% 1.84G/3.50G [00:05<00:05, 300MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  54% 1.88G/3.50G [00:06<00:05, 308MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  55% 1.92G/3.50G [00:06<00:04, 322MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  56% 1.96G/3.50G [00:06<00:04, 328MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  57% 2.00G/3.50G [00:06<00:04, 325MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  58% 2.04G/3.50G [00:06<00:04, 320MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  60% 2.09G/3.50G [00:06<00:04, 317MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  61% 2.13G/3.50G [00:06<00:04, 327MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  62% 2.17G/3.50G [00:06<00:04, 325MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  63% 2.21G/3.50G [00:07<00:03, 335MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  64% 2.25G/3.50G [00:07<00:03, 344MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  66% 2.30G/3.50G [00:07<00:03, 327MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  67% 2.34G/3.50G [00:07<00:03, 319MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  68% 2.38G/3.50G [00:07<00:03, 316MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  69% 2.42G/3.50G [00:07<00:03, 322MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  70% 2.46G/3.50G [00:07<00:03, 328MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  72% 2.51G/3.50G [00:07<00:03, 328MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  73% 2.55G/3.50G [00:08<00:02, 333MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  74% 2.59G/3.50G [00:08<00:02, 330MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  75% 2.63G/3.50G [00:08<00:02, 326MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  76% 2.67G/3.50G [00:08<00:02, 324MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  78% 2.72G/3.50G [00:08<00:02, 332MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  79% 2.76G/3.50G [00:08<00:02, 331MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  80% 2.80G/3.50G [00:08<00:02, 338MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  81% 2.84G/3.50G [00:08<00:01, 330MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  82% 2.88G/3.50G [00:09<00:01, 327MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  84% 2.93G/3.50G [00:09<00:01, 341MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  85% 2.97G/3.50G [00:09<00:01, 336MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  86% 3.01G/3.50G [00:09<00:01, 345MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  87% 3.05G/3.50G [00:09<00:01, 323MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  88% 3.09G/3.50G [00:09<00:01, 320MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  90% 3.14G/3.50G [00:09<00:01, 328MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  91% 3.18G/3.50G [00:09<00:00, 337MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  92% 3.22G/3.50G [00:10<00:01, 276MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  93% 3.25G/3.50G [00:10<00:00, 265MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  94% 3.29G/3.50G [00:10<00:00, 284MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  95% 3.33G/3.50G [00:10<00:00, 309MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  96% 3.38G/3.50G [00:10<00:00, 263MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  98% 3.42G/3.50G [00:10<00:00, 282MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin:  99% 3.46G/3.50G [00:10<00:00, 294MB/s]\u001b[A\n","pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [00:11<00:00, 306MB/s]\n","Downloading shards: 100% 2/2 [00:51<00:00, 25.50s/it]\n","Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.32s/it]\n","generation_config.json: 100% 132/132 [00:00<00:00, 771kB/s]\n","tokenizer_config.json: 100% 776/776 [00:00<00:00, 4.37MB/s]\n","tokenizer.model: 100% 500k/500k [00:00<00:00, 77.8MB/s]\n","tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 3.84MB/s]\n","special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.38MB/s]\n","2024-03-19:14:01:31,384 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","2024-03-19:14:01:33,578 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt5 from None to 5\n","2024-03-19:14:01:33,579 INFO     [task.py:386] Building contexts for prompt5 on rank 0...\n","100% 1302/1302 [00:06<00:00, 200.48it/s]\n","2024-03-19:14:01:40,116 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [45:47<00:00,  1.42it/s]\n","hf (pretrained=HiTZ/latxa-7b-v1), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt5|Yaml   |none  |     5|acc   |0.5783|±  |0.0137|\n","\n"]}]},{"cell_type":"code","source":["files.download('pretrained__HiTZ__latxa-7b-v1_prompt5.jsonl')\n","files.download('prompt5_latxa.json')"],"metadata":{"id":"YZowOqeWaes-","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1710859663299,"user_tz":-60,"elapsed":587,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"a9b3ef65-674a-4e40-ac36-e97921f233c1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_87d0dfb8-73f6-4379-8601-ebbd74416d88\", \"pretrained__HiTZ__latxa-7b-v1_prompt5.jsonl\", 5292819)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_c8d3b3b1-635a-463c-b483-d2491b3a6e13\", \"prompt5_latxa.json\", 5459)"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Evaluate meta-llama/Llama-2-7b"],"metadata":{"id":"-ywoQF8M0sFN"}},{"cell_type":"markdown","source":["After evaluating HiTZ/latxa-7b-v1, we intend to assess its predecessor in order to compare their performance. To achieve this goal, first, we need to request access to the model through Hugging Face. Once the request has been accepted by the repo authors, we are able to carry out the evaluation."],"metadata":{"id":"dsBQPza8yvIG"}},{"cell_type":"code","source":["!pip install huggingface-hub"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDYTWYs0HD-O","executionInfo":{"status":"ok","timestamp":1710855306069,"user_tz":-60,"elapsed":5313,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"142aab33-e3a5-4104-d91b-1e599c758ea8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (24.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub) (2024.2.2)\n"]}]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RjjHWy0HGdV","executionInfo":{"status":"ok","timestamp":1710855483488,"user_tz":-60,"elapsed":15306,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"2e1292c8-6f92-4631-f9e3-25aa645313ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Token: \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"markdown","source":["Following the same approach as before, we will employ the same prompts to evaluate Llama 2."],"metadata":{"id":"-85Ru1k7z_83"}},{"cell_type":"markdown","source":["### Prompt 1"],"metadata":{"id":"8e_vHQ3MWmNT"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=meta-llama/Llama-2-7b-hf \\\n","    --tasks prompt1 \\\n","    --device cuda \\\n","    --output_path ./prompt1_llama.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"id":"3HgyetkN0yvR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709841551278,"user_tz":-60,"elapsed":574038,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"09dabcf0-b03f-4d15-dd09-25ec31272857"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-07 19:49:40.139061: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-07 19:49:40.139118: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-07 19:49:40.140609: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-07 19:49:41.351687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-07:19:49:45,374 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-07:19:49:45,374 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-07:19:49:51,468 INFO     [__main__.py:293] Selected Tasks: ['prompt1']\n","2024-03-07:19:49:51,468 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-07:19:49:51,469 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-07:19:49:51,498 INFO     [huggingface.py:162] Using device 'cuda'\n","Loading checkpoint shards: 100% 2/2 [01:02<00:00, 31.16s/it]\n","2024-03-07:19:50:55,541 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","2024-03-07:19:51:00,398 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt1 from None to 5\n","2024-03-07:19:51:00,399 INFO     [task.py:386] Building contexts for prompt1 on rank 0...\n","100% 1302/1302 [00:07<00:00, 172.26it/s]\n","2024-03-07:19:51:07,999 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [07:52<00:00,  8.27it/s]\n","hf (pretrained=meta-llama/Llama-2-7b-hf), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt1|Yaml   |none  |     5|acc   |0.4155|±  |0.0137|\n","\n"]}]},{"cell_type":"code","source":["files.download('pretrained__meta-llama__Llama-2-7b-hf_prompt1.jsonl')\n","files.download('prompt1_llama.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"-lnMxtI9dN6S","executionInfo":{"status":"ok","timestamp":1709841555188,"user_tz":-60,"elapsed":554,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"4e1dfc0f-e0ee-4d6a-aa81-bfbc5045bffe"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_b23f79c5-5798-4563-9164-2a1d3b093ba1\", \"pretrained__meta-llama__Llama-2-7b-hf_prompt1.jsonl\", 5480837)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_1a30ac34-1bba-4fa7-bcc7-f72bf487a517\", \"prompt1_llama.json\", 5384)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Prompt 2"],"metadata":{"id":"YlAgw6xfWqRS"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=meta-llama/Llama-2-7b-hf \\\n","    --tasks prompt2 \\\n","    --device cuda \\\n","    --output_path ./prompt2_llama.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bcGuHHg6WpZt","executionInfo":{"status":"ok","timestamp":1709842230130,"user_tz":-60,"elapsed":597205,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"092d790e-12aa-49cc-9356-d972808191e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-07 20:00:37.282792: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-07 20:00:37.282850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-07 20:00:37.284337: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-07 20:00:38.627450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-07:20:00:43,206 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-07:20:00:43,206 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-07:20:00:50,372 INFO     [__main__.py:293] Selected Tasks: ['prompt2']\n","2024-03-07:20:00:50,372 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-07:20:00:50,374 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-07:20:00:50,408 INFO     [huggingface.py:162] Using device 'cuda'\n","Loading checkpoint shards: 100% 2/2 [01:05<00:00, 32.58s/it]\n","2024-03-07:20:01:57,269 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","2024-03-07:20:02:00,728 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt2 from None to 5\n","2024-03-07:20:02:00,729 INFO     [task.py:386] Building contexts for prompt2 on rank 0...\n","100% 1302/1302 [00:07<00:00, 183.73it/s]\n","2024-03-07:20:02:07,857 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [08:09<00:00,  7.97it/s]\n","hf (pretrained=meta-llama/Llama-2-7b-hf), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt2|Yaml   |none  |     5|acc   |0.4132|±  |0.0137|\n","\n"]}]},{"cell_type":"code","source":["files.download('pretrained__meta-llama__Llama-2-7b-hf_prompt2.jsonl')\n","files.download('prompt2_llama.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"tClvRWDtiheB","executionInfo":{"status":"ok","timestamp":1709842249998,"user_tz":-60,"elapsed":25,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"da602ae7-4f7a-4a95-ab16-152cb8b4ff35"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_67a568d3-012f-4cdf-8745-3222ebcd2b6e\", \"pretrained__meta-llama__Llama-2-7b-hf_prompt2.jsonl\", 5691645)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_c0c912e2-2430-40cf-8c28-3d51036e7f9e\", \"prompt2_llama.json\", 5391)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Prompt 3"],"metadata":{"id":"HleTm7oLWs-Z"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=meta-llama/Llama-2-7b-hf \\\n","    --tasks prompt3 \\\n","    --device cuda \\\n","    --output_path ./prompt3_llama.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9_pRV7RWvKa","executionInfo":{"status":"ok","timestamp":1709842912997,"user_tz":-60,"elapsed":602730,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"d514bbe8-44ca-49a9-b10f-d1eb9ff1e961"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-07 20:11:54.542718: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-07 20:11:54.542777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-07 20:11:54.544239: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-07 20:11:55.864066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-07:20:12:00,425 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-07:20:12:00,425 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-07:20:12:07,450 INFO     [__main__.py:293] Selected Tasks: ['prompt3']\n","2024-03-07:20:12:07,450 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-07:20:12:07,451 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-07:20:12:07,480 INFO     [huggingface.py:162] Using device 'cuda'\n","Loading checkpoint shards: 100% 2/2 [01:01<00:00, 30.98s/it]\n","2024-03-07:20:13:11,057 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","2024-03-07:20:13:14,898 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt3 from None to 5\n","2024-03-07:20:13:14,899 INFO     [task.py:386] Building contexts for prompt3 on rank 0...\n","100% 1302/1302 [00:07<00:00, 171.59it/s]\n","2024-03-07:20:13:22,554 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [08:16<00:00,  7.86it/s]\n","hf (pretrained=meta-llama/Llama-2-7b-hf), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt3|Yaml   |none  |     5|acc   |0.3948|±  |0.0136|\n","\n"]}]},{"cell_type":"code","source":["files.download('pretrained__meta-llama__Llama-2-7b-hf_prompt3.jsonl')\n","files.download('prompt3_llama.json')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"OiNCzo37lrDd","executionInfo":{"status":"ok","timestamp":1709843077151,"user_tz":-60,"elapsed":758,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"e5846e42-a0be-47f6-901a-5b9a4868f6f3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_76cd234d-ac0b-4468-bca0-9cda85fdf5b2\", \"pretrained__meta-llama__Llama-2-7b-hf_prompt3.jsonl\", 6043503)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_9701e95b-a4e1-40d1-ab37-276a355d47b0\", \"prompt3_llama.json\", 5409)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Prompt 4"],"metadata":{"id":"bamP9wxFdZz0"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=meta-llama/Llama-2-7b-hf \\\n","    --tasks prompt4 \\\n","    --device cuda \\\n","    --output_path ./prompt4_llama.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"id":"jbjhhRAodepF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710856090894,"user_tz":-60,"elapsed":598552,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"61bcba33-23a7-4d1d-dc25-e0680ad42f7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-19 13:38:17.178386: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-19 13:38:17.178433: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-19 13:38:17.179845: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-19 13:38:18.428139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Downloading builder script: 100% 5.67k/5.67k [00:00<00:00, 18.1MB/s]\n","2024-03-19:13:38:24,595 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-19:13:38:24,595 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-19:13:38:30,600 INFO     [__main__.py:293] Selected Tasks: ['prompt4']\n","2024-03-19:13:38:30,600 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-19:13:38:30,605 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-19:13:38:30,679 INFO     [huggingface.py:162] Using device 'cuda'\n","config.json: 100% 609/609 [00:00<00:00, 2.93MB/s]\n","model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 74.5MB/s]\n","Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n","model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n","model-00001-of-00002.safetensors:   0% 21.0M/9.98G [00:00<00:54, 184MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   1% 52.4M/9.98G [00:00<00:42, 234MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   1% 94.4M/9.98G [00:00<00:33, 291MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   1% 136M/9.98G [00:00<00:30, 319MB/s] \u001b[A\n","model-00001-of-00002.safetensors:   2% 178M/9.98G [00:00<00:28, 339MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   2% 220M/9.98G [00:00<00:27, 349MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   3% 262M/9.98G [00:00<00:26, 360MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   3% 304M/9.98G [00:00<00:26, 360MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   3% 346M/9.98G [00:01<00:26, 363MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   4% 388M/9.98G [00:01<00:25, 370MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   4% 430M/9.98G [00:01<00:25, 373MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   5% 472M/9.98G [00:01<00:25, 377MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   5% 514M/9.98G [00:01<00:24, 383MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   6% 556M/9.98G [00:01<00:24, 381MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   6% 598M/9.98G [00:01<00:24, 385MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   6% 640M/9.98G [00:01<00:24, 378MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   7% 682M/9.98G [00:01<00:24, 373MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   7% 724M/9.98G [00:02<00:24, 371MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   8% 765M/9.98G [00:02<00:24, 370MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   8% 807M/9.98G [00:02<00:25, 366MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   9% 849M/9.98G [00:02<00:25, 353MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   9% 891M/9.98G [00:02<00:25, 357MB/s]\u001b[A\n","model-00001-of-00002.safetensors:   9% 933M/9.98G [00:02<00:27, 331MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  10% 975M/9.98G [00:02<00:27, 323MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  10% 1.02G/9.98G [00:02<00:28, 311MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  11% 1.06G/9.98G [00:03<00:27, 321MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  11% 1.10G/9.98G [00:03<00:26, 333MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  11% 1.14G/9.98G [00:03<00:26, 336MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  12% 1.18G/9.98G [00:03<00:25, 342MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  12% 1.23G/9.98G [00:03<00:25, 342MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  13% 1.27G/9.98G [00:03<00:25, 342MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  13% 1.31G/9.98G [00:08<05:39, 25.5MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  14% 1.35G/9.98G [00:08<04:03, 35.4MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  14% 1.39G/9.98G [00:09<02:56, 48.6MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  14% 1.44G/9.98G [00:09<02:09, 65.7MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  15% 1.48G/9.98G [00:09<01:37, 87.5MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  15% 1.52G/9.98G [00:09<01:14, 114MB/s] \u001b[A\n","model-00001-of-00002.safetensors:  16% 1.56G/9.98G [00:09<00:58, 144MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  16% 1.60G/9.98G [00:09<00:47, 177MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  17% 1.65G/9.98G [00:09<00:39, 210MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  17% 1.69G/9.98G [00:09<00:34, 243MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  17% 1.73G/9.98G [00:09<00:30, 272MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  18% 1.77G/9.98G [00:10<00:27, 300MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  18% 1.81G/9.98G [00:10<00:25, 322MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  19% 1.86G/9.98G [00:10<00:36, 225MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  19% 1.90G/9.98G [00:10<00:32, 251MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  19% 1.94G/9.98G [00:10<00:30, 261MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  20% 1.98G/9.98G [00:10<00:29, 274MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  20% 2.01G/9.98G [00:11<00:28, 276MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  20% 2.04G/9.98G [00:11<00:28, 279MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  21% 2.08G/9.98G [00:11<00:28, 281MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  21% 2.12G/9.98G [00:11<00:26, 297MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  22% 2.16G/9.98G [00:11<00:24, 315MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  22% 2.20G/9.98G [00:11<00:23, 325MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  22% 2.24G/9.98G [00:11<00:23, 335MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  23% 2.29G/9.98G [00:11<00:22, 342MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  23% 2.33G/9.98G [00:11<00:22, 347MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  24% 2.37G/9.98G [00:12<00:21, 351MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  24% 2.41G/9.98G [00:12<00:21, 353MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  25% 2.45G/9.98G [00:12<00:21, 355MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  25% 2.50G/9.98G [00:12<00:21, 356MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  25% 2.54G/9.98G [00:12<00:20, 358MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  26% 2.58G/9.98G [00:12<00:20, 356MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  26% 2.62G/9.98G [00:12<00:20, 359MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  27% 2.66G/9.98G [00:12<00:20, 361MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:12<00:20, 363MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  28% 2.75G/9.98G [00:13<00:19, 364MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  28% 2.79G/9.98G [00:13<00:19, 361MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  28% 2.83G/9.98G [00:13<00:19, 370MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  29% 2.87G/9.98G [00:13<00:19, 371MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  29% 2.92G/9.98G [00:13<00:19, 370MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  30% 2.96G/9.98G [00:13<00:19, 369MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  30% 3.00G/9.98G [00:13<00:19, 366MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  30% 3.04G/9.98G [00:13<00:19, 359MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  31% 3.08G/9.98G [00:14<00:19, 352MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  31% 3.12G/9.98G [00:14<00:19, 355MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  32% 3.17G/9.98G [00:14<00:19, 352MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  32% 3.21G/9.98G [00:14<00:19, 344MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  33% 3.25G/9.98G [00:14<00:20, 336MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  33% 3.29G/9.98G [00:14<00:21, 317MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  33% 3.33G/9.98G [00:14<00:21, 316MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  34% 3.38G/9.98G [00:14<00:21, 308MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  34% 3.41G/9.98G [00:15<00:21, 302MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  34% 3.44G/9.98G [00:15<00:21, 304MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  35% 3.47G/9.98G [00:15<00:21, 306MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  35% 3.50G/9.98G [00:15<00:21, 301MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  35% 3.53G/9.98G [00:15<00:21, 302MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  36% 3.57G/9.98G [00:15<00:21, 304MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  36% 3.60G/9.98G [00:15<00:21, 298MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  36% 3.64G/9.98G [00:15<00:20, 304MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  37% 3.67G/9.98G [00:15<00:20, 304MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  37% 3.70G/9.98G [00:16<00:20, 301MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  37% 3.73G/9.98G [00:16<00:20, 304MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  38% 3.77G/9.98G [00:16<00:19, 317MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  38% 3.82G/9.98G [00:16<00:18, 326MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  39% 3.86G/9.98G [00:16<00:18, 336MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  39% 3.90G/9.98G [00:16<00:17, 344MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  40% 3.94G/9.98G [00:16<00:17, 349MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  40% 3.98G/9.98G [00:16<00:17, 350MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  40% 4.03G/9.98G [00:16<00:16, 351MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  41% 4.07G/9.98G [00:17<00:16, 357MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  41% 4.11G/9.98G [00:17<00:16, 355MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  42% 4.15G/9.98G [00:17<00:16, 353MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  42% 4.19G/9.98G [00:17<00:16, 349MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  42% 4.24G/9.98G [00:17<00:16, 350MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:17<00:16, 352MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  43% 4.32G/9.98G [00:17<00:16, 351MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  44% 4.36G/9.98G [00:17<00:15, 353MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  44% 4.40G/9.98G [00:18<00:15, 354MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  45% 4.45G/9.98G [00:18<00:15, 355MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  45% 4.49G/9.98G [00:18<00:15, 353MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  45% 4.53G/9.98G [00:18<00:15, 360MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  46% 4.57G/9.98G [00:18<00:15, 356MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  46% 4.61G/9.98G [00:18<00:15, 351MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  47% 4.66G/9.98G [00:18<00:16, 327MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  47% 4.70G/9.98G [00:18<00:16, 326MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  48% 4.74G/9.98G [00:19<00:16, 319MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  48% 4.78G/9.98G [00:19<00:16, 321MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  48% 4.82G/9.98G [00:19<00:16, 316MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  49% 4.87G/9.98G [00:19<00:16, 315MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  49% 4.91G/9.98G [00:19<00:16, 309MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  50% 4.94G/9.98G [00:19<00:16, 307MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  50% 4.97G/9.98G [00:19<00:16, 296MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  50% 5.00G/9.98G [00:19<00:16, 295MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  50% 5.03G/9.98G [00:20<00:17, 287MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  51% 5.06G/9.98G [00:20<00:17, 285MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  51% 5.11G/9.98G [00:20<00:16, 298MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  52% 5.15G/9.98G [00:20<00:15, 306MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  52% 5.18G/9.98G [00:20<00:23, 200MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  52% 5.21G/9.98G [00:20<00:21, 221MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  53% 5.25G/9.98G [00:20<00:18, 254MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  53% 5.30G/9.98G [00:21<00:16, 281MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  53% 5.34G/9.98G [00:21<00:15, 307MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  54% 5.38G/9.98G [00:21<00:14, 326MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  54% 5.42G/9.98G [00:21<00:13, 331MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  55% 5.46G/9.98G [00:21<00:13, 340MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  55% 5.51G/9.98G [00:21<00:12, 351MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  56% 5.55G/9.98G [00:21<00:12, 354MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  56% 5.59G/9.98G [00:21<00:12, 354MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  56% 5.63G/9.98G [00:21<00:12, 357MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  57% 5.67G/9.98G [00:22<00:11, 360MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  57% 5.71G/9.98G [00:22<00:11, 363MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  58% 5.76G/9.98G [00:22<00:11, 358MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  58% 5.80G/9.98G [00:22<00:11, 359MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  59% 5.84G/9.98G [00:22<00:11, 358MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  59% 5.88G/9.98G [00:22<00:11, 358MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  59% 5.92G/9.98G [00:22<00:11, 345MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  60% 5.97G/9.98G [00:22<00:11, 340MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  60% 6.01G/9.98G [00:23<00:11, 334MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  61% 6.05G/9.98G [00:23<00:11, 332MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  61% 6.09G/9.98G [00:23<00:12, 322MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  61% 6.13G/9.98G [00:23<00:12, 317MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  62% 6.18G/9.98G [00:23<00:12, 312MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  62% 6.22G/9.98G [00:23<00:12, 313MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  63% 6.25G/9.98G [00:23<00:12, 309MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  63% 6.28G/9.98G [00:23<00:11, 308MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  63% 6.32G/9.98G [00:24<00:11, 313MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  64% 6.35G/9.98G [00:24<00:11, 308MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  64% 6.40G/9.98G [00:24<00:11, 314MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  65% 6.44G/9.98G [00:24<00:10, 323MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  65% 6.48G/9.98G [00:24<00:10, 324MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  65% 6.52G/9.98G [00:24<00:10, 325MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  66% 6.56G/9.98G [00:24<00:10, 327MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  66% 6.61G/9.98G [00:24<00:10, 325MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  67% 6.65G/9.98G [00:25<00:10, 323MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  67% 6.69G/9.98G [00:25<00:10, 316MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  67% 6.73G/9.98G [00:25<00:10, 313MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  68% 6.76G/9.98G [00:25<00:10, 309MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  68% 6.79G/9.98G [00:25<00:10, 296MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  68% 6.83G/9.98G [00:25<00:10, 300MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  69% 6.86G/9.98G [00:25<00:10, 293MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  69% 6.89G/9.98G [00:25<00:10, 299MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  69% 6.93G/9.98G [00:26<00:09, 309MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  70% 6.96G/9.98G [00:26<00:09, 310MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  70% 6.99G/9.98G [00:26<00:09, 308MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  71% 7.04G/9.98G [00:26<00:09, 320MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  71% 7.08G/9.98G [00:26<00:08, 332MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  71% 7.12G/9.98G [00:26<00:08, 339MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  72% 7.16G/9.98G [00:26<00:08, 348MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  72% 7.20G/9.98G [00:26<00:07, 355MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  73% 7.25G/9.98G [00:26<00:07, 360MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  73% 7.29G/9.98G [00:27<00:07, 357MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  73% 7.33G/9.98G [00:27<00:07, 351MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  74% 7.37G/9.98G [00:27<00:07, 358MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  74% 7.41G/9.98G [00:27<00:07, 354MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  75% 7.46G/9.98G [00:27<00:07, 354MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  75% 7.50G/9.98G [00:27<00:06, 355MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  76% 7.54G/9.98G [00:27<00:06, 357MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  76% 7.58G/9.98G [00:27<00:06, 356MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  76% 7.62G/9.98G [00:27<00:06, 355MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  77% 7.67G/9.98G [00:28<00:06, 357MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  77% 7.71G/9.98G [00:28<00:06, 352MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  78% 7.75G/9.98G [00:28<00:06, 333MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  78% 7.79G/9.98G [00:28<00:06, 331MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  79% 7.83G/9.98G [00:28<00:06, 326MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  79% 7.87G/9.98G [00:28<00:06, 323MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  79% 7.92G/9.98G [00:28<00:06, 322MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  80% 7.96G/9.98G [00:29<00:06, 315MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  80% 8.00G/9.98G [00:29<00:06, 298MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  81% 8.04G/9.98G [00:29<00:06, 304MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  81% 8.08G/9.98G [00:29<00:06, 310MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  81% 8.12G/9.98G [00:29<00:05, 311MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  82% 8.15G/9.98G [00:29<00:05, 307MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  82% 8.18G/9.98G [00:29<00:06, 299MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  82% 8.21G/9.98G [00:29<00:06, 290MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  83% 8.25G/9.98G [00:30<00:05, 299MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  83% 8.28G/9.98G [00:30<00:05, 301MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  83% 8.32G/9.98G [00:30<00:05, 304MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  84% 8.35G/9.98G [00:30<00:05, 302MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  84% 8.38G/9.98G [00:30<00:05, 301MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  84% 8.41G/9.98G [00:30<00:05, 303MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  85% 8.44G/9.98G [00:30<00:05, 305MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  85% 8.47G/9.98G [00:30<00:07, 194MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  85% 8.51G/9.98G [00:31<00:06, 234MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  86% 8.56G/9.98G [00:31<00:05, 269MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  86% 8.60G/9.98G [00:31<00:04, 295MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  87% 8.64G/9.98G [00:31<00:04, 315MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  87% 8.68G/9.98G [00:31<00:04, 286MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  87% 8.72G/9.98G [00:31<00:04, 297MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  88% 8.77G/9.98G [00:31<00:03, 312MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  88% 8.81G/9.98G [00:31<00:03, 329MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  89% 8.85G/9.98G [00:32<00:03, 337MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  89% 8.89G/9.98G [00:32<00:03, 343MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  90% 8.93G/9.98G [00:32<00:02, 349MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  90% 8.98G/9.98G [00:32<00:02, 355MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  90% 9.02G/9.98G [00:32<00:02, 356MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  91% 9.06G/9.98G [00:32<00:02, 353MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  91% 9.10G/9.98G [00:32<00:02, 351MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  92% 9.14G/9.98G [00:32<00:02, 353MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  92% 9.19G/9.98G [00:32<00:02, 354MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  92% 9.23G/9.98G [00:33<00:02, 338MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  93% 9.27G/9.98G [00:33<00:02, 317MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  93% 9.31G/9.98G [00:33<00:02, 306MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  94% 9.34G/9.98G [00:33<00:02, 306MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  94% 9.37G/9.98G [00:33<00:01, 307MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  94% 9.41G/9.98G [00:33<00:01, 307MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  95% 9.44G/9.98G [00:33<00:01, 307MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  95% 9.47G/9.98G [00:33<00:01, 306MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  95% 9.51G/9.98G [00:34<00:01, 309MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  96% 9.55G/9.98G [00:34<00:01, 312MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  96% 9.58G/9.98G [00:34<00:01, 306MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  96% 9.62G/9.98G [00:34<00:01, 304MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  97% 9.65G/9.98G [00:34<00:01, 306MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  97% 9.69G/9.98G [00:34<00:00, 311MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  98% 9.73G/9.98G [00:34<00:00, 313MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  98% 9.76G/9.98G [00:34<00:00, 312MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  98% 9.79G/9.98G [00:34<00:00, 313MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  98% 9.83G/9.98G [00:35<00:00, 308MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  99% 9.86G/9.98G [00:35<00:00, 293MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  99% 9.89G/9.98G [00:35<00:00, 285MB/s]\u001b[A\n","model-00001-of-00002.safetensors:  99% 9.92G/9.98G [00:35<00:00, 290MB/s]\u001b[A\n","model-00001-of-00002.safetensors: 100% 9.98G/9.98G [00:35<00:00, 280MB/s]\n","Downloading shards:  50% 1/2 [00:35<00:35, 35.86s/it]\n","model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n","model-00002-of-00002.safetensors:   1% 41.9M/3.50G [00:00<00:09, 359MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   2% 83.9M/3.50G [00:00<00:09, 362MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   4% 126M/3.50G [00:00<00:09, 339MB/s] \u001b[A\n","model-00002-of-00002.safetensors:   5% 168M/3.50G [00:00<00:09, 354MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   6% 210M/3.50G [00:00<00:08, 368MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   7% 252M/3.50G [00:00<00:08, 374MB/s]\u001b[A\n","model-00002-of-00002.safetensors:   8% 294M/3.50G [00:00<00:08, 369MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  10% 336M/3.50G [00:00<00:08, 368MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  11% 377M/3.50G [00:01<00:08, 368MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  12% 419M/3.50G [00:01<00:08, 360MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  13% 461M/3.50G [00:01<00:08, 369MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  14% 503M/3.50G [00:01<00:08, 366MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  16% 545M/3.50G [00:01<00:08, 344MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  17% 587M/3.50G [00:01<00:08, 339MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  18% 629M/3.50G [00:01<00:08, 348MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  19% 671M/3.50G [00:01<00:08, 347MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  20% 713M/3.50G [00:02<00:08, 337MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  22% 755M/3.50G [00:02<00:08, 336MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  23% 797M/3.50G [00:02<00:08, 322MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  24% 839M/3.50G [00:02<00:08, 306MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  25% 870M/3.50G [00:02<00:08, 297MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  26% 902M/3.50G [00:02<00:09, 286MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  27% 933M/3.50G [00:02<00:08, 287MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  28% 965M/3.50G [00:02<00:08, 289MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  28% 996M/3.50G [00:02<00:08, 292MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  29% 1.03G/3.50G [00:03<00:08, 294MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  31% 1.07G/3.50G [00:03<00:08, 301MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  32% 1.11G/3.50G [00:03<00:07, 307MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  33% 1.14G/3.50G [00:03<00:08, 290MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  34% 1.17G/3.50G [00:03<00:07, 293MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  34% 1.21G/3.50G [00:03<00:07, 290MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  35% 1.24G/3.50G [00:03<00:07, 291MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  36% 1.27G/3.50G [00:03<00:07, 296MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  37% 1.30G/3.50G [00:04<00:07, 289MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  38% 1.33G/3.50G [00:04<00:07, 290MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  39% 1.37G/3.50G [00:04<00:07, 302MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  40% 1.41G/3.50G [00:04<00:06, 300MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  41% 1.44G/3.50G [00:04<00:06, 301MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  42% 1.48G/3.50G [00:04<00:06, 312MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  43% 1.52G/3.50G [00:04<00:06, 313MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  45% 1.56G/3.50G [00:04<00:06, 314MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  46% 1.60G/3.50G [00:04<00:05, 324MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  47% 1.65G/3.50G [00:05<00:05, 326MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  48% 1.69G/3.50G [00:05<00:05, 339MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:05<00:05, 346MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  51% 1.77G/3.50G [00:05<00:04, 349MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  52% 1.81G/3.50G [00:05<00:04, 350MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  53% 1.86G/3.50G [00:05<00:04, 349MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  54% 1.90G/3.50G [00:05<00:04, 355MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  55% 1.94G/3.50G [00:06<00:06, 233MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:06<00:05, 261MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  58% 2.02G/3.50G [00:06<00:05, 281MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  59% 2.07G/3.50G [00:06<00:04, 296MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  60% 2.11G/3.50G [00:06<00:04, 308MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  61% 2.15G/3.50G [00:06<00:04, 298MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  63% 2.19G/3.50G [00:06<00:04, 313MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  64% 2.23G/3.50G [00:07<00:03, 320MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  65% 2.28G/3.50G [00:07<00:03, 326MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  66% 2.32G/3.50G [00:07<00:03, 321MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  67% 2.36G/3.50G [00:07<00:03, 321MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  69% 2.40G/3.50G [00:07<00:03, 328MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  70% 2.44G/3.50G [00:07<00:03, 329MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  71% 2.49G/3.50G [00:07<00:02, 341MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  72% 2.53G/3.50G [00:07<00:02, 351MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  73% 2.57G/3.50G [00:07<00:02, 354MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  75% 2.61G/3.50G [00:08<00:02, 353MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  76% 2.65G/3.50G [00:08<00:02, 352MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  77% 2.69G/3.50G [00:08<00:02, 360MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  78% 2.74G/3.50G [00:08<00:02, 357MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  79% 2.78G/3.50G [00:08<00:01, 363MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  81% 2.82G/3.50G [00:08<00:01, 358MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  82% 2.86G/3.50G [00:08<00:01, 346MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  83% 2.90G/3.50G [00:08<00:01, 350MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  84% 2.95G/3.50G [00:09<00:01, 351MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  85% 2.99G/3.50G [00:09<00:01, 351MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  87% 3.03G/3.50G [00:09<00:01, 352MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  88% 3.07G/3.50G [00:09<00:01, 354MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  89% 3.11G/3.50G [00:09<00:01, 359MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  90% 3.16G/3.50G [00:09<00:00, 354MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  91% 3.20G/3.50G [00:09<00:00, 346MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  93% 3.24G/3.50G [00:09<00:00, 335MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  94% 3.28G/3.50G [00:10<00:00, 333MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  95% 3.32G/3.50G [00:10<00:00, 329MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  96% 3.37G/3.50G [00:10<00:00, 322MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  97% 3.41G/3.50G [00:10<00:00, 323MB/s]\u001b[A\n","model-00002-of-00002.safetensors:  99% 3.45G/3.50G [00:10<00:00, 326MB/s]\u001b[A\n","model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:10<00:00, 327MB/s]\n","Downloading shards: 100% 2/2 [00:46<00:00, 23.36s/it]\n","Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.37s/it]\n","generation_config.json: 100% 188/188 [00:00<00:00, 1.09MB/s]\n","tokenizer_config.json: 100% 776/776 [00:00<00:00, 4.36MB/s]\n","tokenizer.model: 100% 500k/500k [00:00<00:00, 265MB/s]\n","tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 4.82MB/s]\n","special_tokens_map.json: 100% 414/414 [00:00<00:00, 2.27MB/s]\n","2024-03-19:13:39:25,727 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","Downloading builder script: 100% 28.3k/28.3k [00:00<00:00, 53.1MB/s]\n","Downloading readme: 100% 26.6k/26.6k [00:00<00:00, 53.1MB/s]\n","Downloading data: 854kB [00:00, 20.3MB/s]       \n","Downloading data: 182kB [00:00, 10.8MB/s]        \n","Downloading data: 182kB [00:00, 9.97MB/s]        \n","Generating train split: 100% 6078/6078 [00:00<00:00, 25530.13 examples/s]\n","Generating test split: 100% 1302/1302 [00:00<00:00, 27021.46 examples/s]\n","Generating validation split: 100% 1302/1302 [00:00<00:00, 27525.12 examples/s]\n","2024-03-19:13:39:30,586 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt4 from None to 5\n","2024-03-19:13:39:30,587 INFO     [task.py:386] Building contexts for prompt4 on rank 0...\n","100% 1302/1302 [00:06<00:00, 194.17it/s]\n","2024-03-19:13:39:37,333 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [08:11<00:00,  7.95it/s]\n","hf (pretrained=meta-llama/Llama-2-7b-hf), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt4|Yaml   |none  |     5|acc   |0.4163|±  |0.0137|\n","\n"]}]},{"cell_type":"code","source":["files.download('pretrained__meta-llama__Llama-2-7b-hf_prompt4.jsonl')\n","files.download('prompt4_llama.json')"],"metadata":{"id":"HlfhG8akdi2C","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1710856157226,"user_tz":-60,"elapsed":526,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"5ab1f750-4d41-4bfe-c216-76ebe78fc48d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_47f008cb-0775-475b-ab70-e4df513afdd8\", \"pretrained__meta-llama__Llama-2-7b-hf_prompt4.jsonl\", 6301295)"]},"metadata":{}}]},{"cell_type":"markdown","source":["### Prompt 5"],"metadata":{"id":"HZOC8R0mdclT"}},{"cell_type":"code","source":["!lm_eval \\\n","    --model hf \\\n","    --model_args pretrained=meta-llama/Llama-2-7b-hf \\\n","    --tasks prompt5 \\\n","    --device cuda \\\n","    --output_path ./prompt5_llama.json \\\n","    --num_fewshot 5 \\\n","    --log_samples"],"metadata":{"id":"w8PMRaFhdnDR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710856703197,"user_tz":-60,"elapsed":487696,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"651c24aa-ff25-415a-a268-0e450df2f96d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024-03-19 13:50:18.380024: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-19 13:50:18.380080: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-19 13:50:18.381507: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-19 13:50:19.726759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2024-03-19:13:50:23,627 INFO     [__main__.py:217] Verbosity set to INFO\n","2024-03-19:13:50:23,627 INFO     [__init__.py:369] lm_eval.tasks.initialize_tasks() is deprecated and no longer necessary. It will be removed in v0.4.2 release. TaskManager will instead be used.\n","2024-03-19:13:50:29,522 INFO     [__main__.py:293] Selected Tasks: ['prompt5']\n","2024-03-19:13:50:29,523 INFO     [__main__.py:294] Loading selected tasks...\n","2024-03-19:13:50:29,524 INFO     [evaluator.py:135] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234\n","2024-03-19:13:50:29,571 INFO     [huggingface.py:162] Using device 'cuda'\n","Loading checkpoint shards: 100% 2/2 [00:05<00:00,  2.65s/it]\n","2024-03-19:13:50:35,799 INFO     [evaluator.py:193] get_task_dict has been updated to accept an optional argument, `task_manager`Read more here:https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md#external-library-usage\n","/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for orai-nlp/basqueGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/orai-nlp/basqueGLUE\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n","  warnings.warn(\n","2024-03-19:13:50:37,930 WARNING  [evaluator.py:225] Overwriting default num_fewshot of prompt5 from None to 5\n","2024-03-19:13:50:37,931 INFO     [task.py:386] Building contexts for prompt5 on rank 0...\n","100% 1302/1302 [00:06<00:00, 196.43it/s]\n","2024-03-19:13:50:44,597 INFO     [evaluator.py:359] Running loglikelihood requests\n","Running loglikelihood requests: 100% 3906/3906 [07:29<00:00,  8.68it/s]\n","hf (pretrained=meta-llama/Llama-2-7b-hf), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1\n","| Tasks |Version|Filter|n-shot|Metric|Value |   |Stderr|\n","|-------|-------|------|-----:|------|-----:|---|-----:|\n","|prompt5|Yaml   |none  |     5|acc   |0.4209|±  |0.0137|\n","\n"]}]},{"cell_type":"code","source":["files.download('pretrained__meta-llama__Llama-2-7b-hf_prompt5.jsonl')\n","files.download('prompt5_llama.json')"],"metadata":{"id":"_j6Kfg_4dqQ3","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1710856754598,"user_tz":-60,"elapsed":339,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"d8e05691-9bf2-487f-c312-657289fedfba"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_aaa8f577-ebbf-4df2-ba9a-f0c7228295b4\", \"pretrained__meta-llama__Llama-2-7b-hf_prompt5.jsonl\", 5293211)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_95a56da8-5542-41c1-9301-13e89fe98d36\", \"prompt5_llama.json\", 5468)"]},"metadata":{}}]},{"cell_type":"markdown","source":["## Random guesser"],"metadata":{"id":"HjVnXCyLMiJG"}},{"cell_type":"markdown","source":["According to [Latxa's model card](https://huggingface.co/HiTZ/latxa-7b-v1), in the case of Basque and other low-resource languages, the performance of LLMs is comparable to that of a random guesser. Latxa was developed to address the challenges posed by limited linguistic resources, using the high-quality language-specific corpus EusCrawl during the training. Therefore, we are going to create a random guesser in order to observe the difference in performance between Latxa and a random guesser. The dataset we are employing is labeled with three classes: negative, neutral, and positive. Therefore, the probability of a model making a correct prediction by chance would be 33.33%."],"metadata":{"id":"C-hE04vG0lHM"}},{"cell_type":"code","source":["from datasets import load_dataset\n","import numpy as np\n","from sklearn.metrics import accuracy_score\n","\n","# Load the dataset from Hugging Face\n","dataset = load_dataset(\"orai-nlp/basqueGLUE\", \"bec\", trust_remote_code=True)\n","\n","# Implement the Random Guesser\n","class RandomGuesser:\n","    def __init__(self, num_classes):\n","        self.num_classes = num_classes\n","\n","    def predict(self, X):\n","        return np.random.randint(0, self.num_classes, size=len(X))\n","\n","# Get the real labels for the test set\n","y_test = dataset['test']['label']\n","\n","# Get the samples without the labels for the test set\n","X_test = dataset['test'][\"text\"]\n","\n","# Evaluate the Random Guesser\n","random_guesser = RandomGuesser(num_classes=3)\n","\n","# Generate random predictions\n","y_pred_random = random_guesser.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred_random)\n","print(\"Accuracy of a random guesser:\", accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nEoYyrivNm5d","executionInfo":{"status":"ok","timestamp":1710867376997,"user_tz":-60,"elapsed":3076,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"c5038556-0654-43cd-897e-779c03f4f211"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy of a random guesser: 0.33102918586789554\n"]}]},{"cell_type":"markdown","source":["## Results"],"metadata":{"id":"A4ph45wio8Mo"}},{"cell_type":"markdown","source":["Finally, we plot the results to visually compare the difference in performance between Latxa and Llama 2 across the five prompts."],"metadata":{"id":"5mQpIPpRAPlM"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LBYXwIFRo6MD","executionInfo":{"status":"ok","timestamp":1710860040645,"user_tz":-60,"elapsed":20856,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"c540de91-647c-4f27-c522-7df9a36b2a7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","import pandas as pd\n","\n","folder_path = '/content/drive/My Drive/Colab Notebooks/DL4NLP/Results_Latxa'\n","file_names = os.listdir(folder_path)\n","results_latxa = {}\n","\n","for file_name in file_names:\n","    file_path = os.path.join(folder_path, file_name)\n","    if file_path.endswith('.json'):\n","        with open(file_path, 'r') as f:\n","            data = json.load(f)\n","            prompt_key = file_name.split('_')[0].lower()\n","            acc = data['results'][prompt_key]['acc,none']\n","            results_latxa[prompt_key] = acc\n","\n","df_latxa = pd.DataFrame(list(results_latxa.items()), columns=['Prompt', 'Accuracy'])\n","results_latxa = df_latxa.reset_index(drop=True)\n","print(\"Latxa:\")\n","print(results_latxa)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"16U7TqS1pG5v","executionInfo":{"status":"ok","timestamp":1710860046778,"user_tz":-60,"elapsed":3327,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"e69c9b5c-b73e-41ae-8e27-a563cbe3c829"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Latxa:\n","    Prompt  Accuracy\n","0  prompt2  0.545315\n","1  prompt3  0.565284\n","2  prompt1  0.556068\n","3  prompt4  0.480031\n","4  prompt5  0.578341\n"]}]},{"cell_type":"code","source":["folder_path = '/content/drive/My Drive/Colab Notebooks/DL4NLP/Results_Llama'\n","file_names = os.listdir(folder_path)\n","results_llama = {}\n","\n","for file_name in file_names:\n","    file_path = os.path.join(folder_path, file_name)\n","    if file_path.endswith('.json'):\n","        with open(file_path, 'r') as f:\n","            data = json.load(f)\n","            prompt_key = file_name.split('_')[0].lower()\n","            acc = data['results'][prompt_key]['acc,none']\n","            results_llama[prompt_key] = acc\n","\n","df_llama = pd.DataFrame(list(results_llama.items()), columns=['Prompt', 'Accuracy'])\n","results_llama = df_llama.reset_index(drop=True)\n","print(\"Llama:\")\n","print(results_llama)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MLeMlb6tqkVf","executionInfo":{"status":"ok","timestamp":1710860057845,"user_tz":-60,"elapsed":2869,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"a07eff5b-ae6a-4ded-99ba-9af7875529b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Llama:\n","    Prompt  Accuracy\n","0  prompt1  0.415515\n","1  prompt2  0.413210\n","2  prompt3  0.394777\n","3  prompt4  0.416283\n","4  prompt5  0.420891\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Create a figure and axis for the plot\n","fig, ax = plt.subplots(figsize=(10, 6))\n","\n","# Define the desired order for the prompts\n","prompt_order = ['prompt1', 'prompt2', 'prompt3', 'prompt4', 'prompt5']\n","\n","# Ensure that DataFrames are in the same order for prompts\n","df_latxa['Prompt'] = pd.Categorical(df_latxa['Prompt'], categories=prompt_order, ordered=True)\n","df_llama['Prompt'] = pd.Categorical(df_llama['Prompt'], categories=prompt_order, ordered=True)\n","df_latxa.sort_values('Prompt', inplace=True)\n","df_llama.sort_values('Prompt', inplace=True)\n","\n","# Bar width\n","bar_width = 0.35\n","\n","# Bar positions\n","index = np.arange(len(prompt_order))\n","\n","# Draw bars for Latxa\n","bars1 = ax.bar(index - bar_width/2, df_latxa['Accuracy'], bar_width, label='Latxa', color='skyblue')\n","\n","# Draw bars for Llama\n","bars2 = ax.bar(index + bar_width/2, df_llama['Accuracy'], bar_width, label='Llama', color='orange')\n","\n","# Set y-axis label\n","ax.set_ylabel('Accuracy')\n","\n","# Set title\n","ax.set_title('Model Performance Comparison in Sentiment Analysis Using 5-shot')\n","\n","# Set x-axis ticks and labels\n","ax.set_xticks(index)\n","ax.set_xticklabels(prompt_order)\n","\n","# Add legend\n","ax.legend()\n","\n","# Show the plot\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":607},"id":"ht67CObYNmWh","executionInfo":{"status":"ok","timestamp":1710860304546,"user_tz":-60,"elapsed":7,"user":{"displayName":"Amaia Murillo Lekuona","userId":"00254280571541743383"}},"outputId":"240a1d62-cd39-40d6-ae38-f13f27df9149"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x600 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}]}